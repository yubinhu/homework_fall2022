


LOGGING TO:  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q3_obstacles_obstacles-cs285-v0_02-11-2022_00-31-58 



########################
logging outputs to  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q3_obstacles_obstacles-cs285-v0_02-11-2022_00-31-58
########################
Using GPU id 0
Using action sampling strategy: random


********** Iteration 0 ************

Collecting data to be used for training...
At timestep:     101 / 5000At timestep:     202 / 5000At timestep:     303 / 5000At timestep:     404 / 5000At timestep:     505 / 5000At timestep:     606 / 5000At timestep:     707 / 5000At timestep:     808 / 5000At timestep:     909 / 5000At timestep:     1010 / 5000At timestep:     1111 / 5000At timestep:     1212 / 5000At timestep:     1313 / 5000At timestep:     1414 / 5000At timestep:     1515 / 5000At timestep:     1616 / 5000At timestep:     1717 / 5000At timestep:     1818 / 5000At timestep:     1919 / 5000At timestep:     2020 / 5000At timestep:     2121 / 5000At timestep:     2222 / 5000At timestep:     2323 / 5000At timestep:     2424 / 5000At timestep:     2525 / 5000At timestep:     2626 / 5000At timestep:     2727 / 5000At timestep:     2828 / 5000At timestep:     2929 / 5000At timestep:     3030 / 5000At timestep:     3131 / 5000At timestep:     3232 / 5000At timestep:     3333 / 5000At timestep:     3434 / 5000At timestep:     3535 / 5000At timestep:     3636 / 5000At timestep:     3737 / 5000At timestep:     3838 / 5000At timestep:     3939 / 5000At timestep:     4040 / 5000At timestep:     4141 / 5000At timestep:     4242 / 5000At timestep:     4343 / 5000At timestep:     4444 / 5000At timestep:     4545 / 5000At timestep:     4646 / 5000At timestep:     4747 / 5000At timestep:     4848 / 5000At timestep:     4949 / 5000At timestep:     5050 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     24 / 400At timestep:     47 / 400At timestep:     76 / 400At timestep:     94 / 400At timestep:     137 / 400At timestep:     166 / 400At timestep:     185 / 400At timestep:     274 / 400At timestep:     313 / 400At timestep:     332 / 400At timestep:     362 / 400At timestep:     386 / 400At timestep:     404 / 400Eval_AverageReturn : -30.263151168823242
Eval_StdReturn : 24.481287002563477
Eval_MaxReturn : -12.71245002746582
Eval_MinReturn : -108.70587158203125
Eval_AverageEpLen : 31.076923076923077
Train_AverageReturn : -163.6405487060547
Train_StdReturn : 34.4285888671875
Train_MaxReturn : -90.67053985595703
Train_MinReturn : -227.8916473388672
Train_AverageEpLen : 101.0
Train_EnvstepsSoFar : 5050
TimeSinceStart : 8.641151428222656
Training Loss : 0.3172035217285156
Initial_DataCollection_AverageReturn : -163.6405487060547
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...
At timestep:     27 / 1000At timestep:     48 / 1000At timestep:     63 / 1000At timestep:     93 / 1000At timestep:     111 / 1000At timestep:     138 / 1000At timestep:     155 / 1000At timestep:     256 / 1000At timestep:     285 / 1000At timestep:     301 / 1000At timestep:     322 / 1000At timestep:     423 / 1000At timestep:     438 / 1000At timestep:     497 / 1000At timestep:     517 / 1000At timestep:     537 / 1000At timestep:     552 / 1000At timestep:     574 / 1000At timestep:     629 / 1000At timestep:     681 / 1000At timestep:     713 / 1000At timestep:     814 / 1000At timestep:     915 / 1000At timestep:     1016 / 1000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     43 / 400At timestep:     60 / 400At timestep:     81 / 400At timestep:     101 / 400At timestep:     131 / 400At timestep:     149 / 400At timestep:     180 / 400At timestep:     206 / 400At timestep:     223 / 400At timestep:     241 / 400At timestep:     266 / 400At timestep:     298 / 400At timestep:     323 / 400At timestep:     399 / 400At timestep:     428 / 400Eval_AverageReturn : -26.98493766784668
Eval_StdReturn : 19.012510299682617
Eval_MaxReturn : -9.171807289123535
Eval_MinReturn : -85.61963653564453
Eval_AverageEpLen : 28.533333333333335
Train_AverageReturn : -56.69278335571289
Train_StdReturn : 64.79425811767578
Train_MaxReturn : -8.476840019226074
Train_MinReturn : -188.48545837402344
Train_AverageEpLen : 42.333333333333336
Train_EnvstepsSoFar : 6066
TimeSinceStart : 35.919981718063354
Training Loss : 0.3889557421207428
Initial_DataCollection_AverageReturn : -163.6405487060547
Done logging...




********** Iteration 2 ************

Collecting data to be used for training...
At timestep:     51 / 1000At timestep:     77 / 1000At timestep:     150 / 1000At timestep:     172 / 1000At timestep:     195 / 1000At timestep:     210 / 1000At timestep:     302 / 1000At timestep:     403 / 1000At timestep:     428 / 1000At timestep:     442 / 1000At timestep:     470 / 1000At timestep:     495 / 1000At timestep:     557 / 1000At timestep:     582 / 1000At timestep:     623 / 1000At timestep:     644 / 1000At timestep:     667 / 1000At timestep:     687 / 1000At timestep:     710 / 1000At timestep:     734 / 1000At timestep:     757 / 1000At timestep:     780 / 1000At timestep:     801 / 1000At timestep:     831 / 1000At timestep:     848 / 1000At timestep:     885 / 1000At timestep:     913 / 1000At timestep:     1014 / 1000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     18 / 400At timestep:     34 / 400At timestep:     77 / 400At timestep:     103 / 400At timestep:     154 / 400At timestep:     178 / 400At timestep:     201 / 400At timestep:     231 / 400At timestep:     332 / 400At timestep:     355 / 400At timestep:     456 / 400Eval_AverageReturn : -42.927852630615234
Eval_StdReturn : 39.1727180480957
Eval_MaxReturn : -10.570991516113281
Eval_MinReturn : -127.0127182006836
Eval_AverageEpLen : 41.45454545454545
Train_AverageReturn : -42.6104621887207
Train_StdReturn : 47.78700637817383
Train_MaxReturn : -8.20486068725586
Train_MinReturn : -186.69723510742188
Train_AverageEpLen : 36.214285714285715
Train_EnvstepsSoFar : 7080
TimeSinceStart : 64.48245096206665
Training Loss : 0.39618968963623047
Initial_DataCollection_AverageReturn : -163.6405487060547
Done logging...




********** Iteration 3 ************

Collecting data to be used for training...
At timestep:     72 / 1000At timestep:     105 / 1000At timestep:     130 / 1000At timestep:     190 / 1000At timestep:     210 / 1000At timestep:     232 / 1000At timestep:     278 / 1000At timestep:     306 / 1000At timestep:     324 / 1000At timestep:     340 / 1000At timestep:     383 / 1000At timestep:     407 / 1000At timestep:     434 / 1000At timestep:     459 / 1000At timestep:     478 / 1000At timestep:     499 / 1000At timestep:     521 / 1000At timestep:     541 / 1000At timestep:     636 / 1000At timestep:     657 / 1000At timestep:     675 / 1000At timestep:     691 / 1000At timestep:     713 / 1000At timestep:     732 / 1000At timestep:     756 / 1000At timestep:     822 / 1000At timestep:     895 / 1000At timestep:     909 / 1000At timestep:     967 / 1000At timestep:     985 / 1000At timestep:     1069 / 1000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     83 / 400At timestep:     119 / 400At timestep:     135 / 400At timestep:     150 / 400At timestep:     188 / 400At timestep:     212 / 400At timestep:     254 / 400At timestep:     333 / 400At timestep:     383 / 400At timestep:     410 / 400Eval_AverageReturn : -41.98633575439453
Eval_StdReturn : 29.84848976135254
Eval_MaxReturn : -9.57956314086914
Eval_MinReturn : -96.36624908447266
Eval_AverageEpLen : 41.0
Train_AverageReturn : -32.567928314208984
Train_StdReturn : 27.71111488342285
Train_MaxReturn : -9.191932678222656
Train_MinReturn : -99.71170043945312
Train_AverageEpLen : 34.483870967741936
Train_EnvstepsSoFar : 8149
TimeSinceStart : 94.05689978599548
Training Loss : 0.39688825607299805
Initial_DataCollection_AverageReturn : -163.6405487060547
Done logging...




********** Iteration 4 ************

Collecting data to be used for training...
At timestep:     43 / 1000At timestep:     69 / 1000At timestep:     98 / 1000At timestep:     133 / 1000At timestep:     232 / 1000At timestep:     264 / 1000At timestep:     309 / 1000At timestep:     326 / 1000At timestep:     349 / 1000At timestep:     374 / 1000At timestep:     405 / 1000At timestep:     462 / 1000At timestep:     477 / 1000At timestep:     521 / 1000At timestep:     549 / 1000At timestep:     570 / 1000At timestep:     597 / 1000At timestep:     640 / 1000At timestep:     674 / 1000At timestep:     723 / 1000At timestep:     738 / 1000At timestep:     761 / 1000At timestep:     796 / 1000At timestep:     816 / 1000At timestep:     844 / 1000At timestep:     862 / 1000At timestep:     887 / 1000At timestep:     910 / 1000At timestep:     925 / 1000At timestep:     939 / 1000At timestep:     965 / 1000At timestep:     981 / 1000At timestep:     1005 / 1000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     22 / 400At timestep:     61 / 400At timestep:     81 / 400At timestep:     110 / 400At timestep:     134 / 400At timestep:     163 / 400At timestep:     176 / 400At timestep:     193 / 400At timestep:     223 / 400At timestep:     250 / 400At timestep:     266 / 400At timestep:     332 / 400At timestep:     359 / 400At timestep:     388 / 400At timestep:     410 / 400Eval_AverageReturn : -25.390939712524414
Eval_StdReturn : 14.333970069885254
Eval_MaxReturn : -7.947649955749512
Eval_MinReturn : -69.27891540527344
Eval_AverageEpLen : 27.333333333333332
Train_AverageReturn : -29.357402801513672
Train_StdReturn : 26.18572425842285
Train_MaxReturn : -8.313626289367676
Train_MinReturn : -155.8484344482422
Train_AverageEpLen : 30.454545454545453
Train_EnvstepsSoFar : 9154
TimeSinceStart : 123.12251830101013
Training Loss : 0.4039864242076874
Initial_DataCollection_AverageReturn : -163.6405487060547
Done logging...




********** Iteration 5 ************

Collecting data to be used for training...
At timestep:     24 / 1000At timestep:     44 / 1000At timestep:     80 / 1000At timestep:     103 / 1000At timestep:     139 / 1000At timestep:     156 / 1000At timestep:     190 / 1000At timestep:     219 / 1000At timestep:     242 / 1000At timestep:     305 / 1000At timestep:     323 / 1000At timestep:     346 / 1000At timestep:     362 / 1000At timestep:     387 / 1000At timestep:     453 / 1000At timestep:     475 / 1000At timestep:     505 / 1000At timestep:     537 / 1000At timestep:     564 / 1000At timestep:     596 / 1000At timestep:     615 / 1000At timestep:     642 / 1000At timestep:     668 / 1000At timestep:     684 / 1000At timestep:     785 / 1000At timestep:     828 / 1000At timestep:     862 / 1000At timestep:     878 / 1000At timestep:     907 / 1000At timestep:     958 / 1000At timestep:     983 / 1000At timestep:     999 / 1000At timestep:     1033 / 1000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     17 / 400At timestep:     51 / 400At timestep:     75 / 400At timestep:     94 / 400At timestep:     159 / 400At timestep:     181 / 400At timestep:     206 / 400At timestep:     289 / 400At timestep:     323 / 400At timestep:     348 / 400At timestep:     377 / 400At timestep:     395 / 400At timestep:     416 / 400Eval_AverageReturn : -32.876522064208984
Eval_StdReturn : 31.23786735534668
Eval_MaxReturn : -11.452277183532715
Eval_MinReturn : -131.42050170898438
Eval_AverageEpLen : 32.0
Train_AverageReturn : -32.87446212768555
Train_StdReturn : 32.47636413574219
Train_MaxReturn : -9.120068550109863
Train_MinReturn : -183.07861328125
Train_AverageEpLen : 31.303030303030305
Train_EnvstepsSoFar : 10187
TimeSinceStart : 155.29040384292603
Training Loss : 0.4069417715072632
Initial_DataCollection_AverageReturn : -163.6405487060547
Done logging...




********** Iteration 6 ************

Collecting data to be used for training...
At timestep:     30 / 1000At timestep:     55 / 1000At timestep:     76 / 1000At timestep:     111 / 1000At timestep:     133 / 1000At timestep:     153 / 1000At timestep:     179 / 1000At timestep:     194 / 1000At timestep:     213 / 1000At timestep:     235 / 1000At timestep:     276 / 1000At timestep:     303 / 1000At timestep:     320 / 1000At timestep:     343 / 1000At timestep:     364 / 1000At timestep:     391 / 1000At timestep:     413 / 1000At timestep:     436 / 1000At timestep:     462 / 1000At timestep:     484 / 1000At timestep:     509 / 1000At timestep:     544 / 1000At timestep:     566 / 1000At timestep:     586 / 1000At timestep:     625 / 1000At timestep:     649 / 1000At timestep:     702 / 1000At timestep:     784 / 1000At timestep:     807 / 1000At timestep:     824 / 1000At timestep:     868 / 1000At timestep:     884 / 1000At timestep:     908 / 1000At timestep:     924 / 1000At timestep:     950 / 1000At timestep:     999 / 1000At timestep:     1026 / 1000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     35 / 400At timestep:     58 / 400At timestep:     89 / 400At timestep:     104 / 400At timestep:     129 / 400At timestep:     150 / 400At timestep:     173 / 400At timestep:     196 / 400At timestep:     238 / 400At timestep:     261 / 400At timestep:     278 / 400At timestep:     300 / 400At timestep:     326 / 400At timestep:     347 / 400At timestep:     401 / 400Eval_AverageReturn : -24.974376678466797
Eval_StdReturn : 14.648033142089844
Eval_MaxReturn : -8.357959747314453
Eval_MinReturn : -60.211185455322266
Eval_AverageEpLen : 26.733333333333334
Train_AverageReturn : -27.078834533691406
Train_StdReturn : 21.350107192993164
Train_MaxReturn : -8.619129180908203
Train_MinReturn : -127.470703125
Train_AverageEpLen : 27.72972972972973
Train_EnvstepsSoFar : 11213
TimeSinceStart : 185.34474658966064
Training Loss : 0.4015129506587982
Initial_DataCollection_AverageReturn : -163.6405487060547
Done logging...




********** Iteration 7 ************

Collecting data to be used for training...
At timestep:     27 / 1000At timestep:     46 / 1000At timestep:     80 / 1000At timestep:     127 / 1000At timestep:     144 / 1000At timestep:     163 / 1000At timestep:     189 / 1000At timestep:     205 / 1000At timestep:     227 / 1000At timestep:     314 / 1000At timestep:     335 / 1000At timestep:     425 / 1000At timestep:     490 / 1000At timestep:     542 / 1000At timestep:     557 / 1000At timestep:     597 / 1000At timestep:     630 / 1000At timestep:     656 / 1000At timestep:     682 / 1000At timestep:     762 / 1000At timestep:     813 / 1000At timestep:     840 / 1000At timestep:     867 / 1000At timestep:     925 / 1000At timestep:     969 / 1000At timestep:     986 / 1000At timestep:     1010 / 1000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     30 / 400At timestep:     46 / 400At timestep:     78 / 400At timestep:     107 / 400At timestep:     158 / 400At timestep:     173 / 400At timestep:     201 / 400At timestep:     227 / 400At timestep:     253 / 400At timestep:     277 / 400At timestep:     344 / 400At timestep:     362 / 400At timestep:     403 / 400Eval_AverageReturn : -28.73512077331543
Eval_StdReturn : 18.74089241027832
Eval_MaxReturn : -8.496576309204102
Eval_MinReturn : -78.26710510253906
Eval_AverageEpLen : 31.0
Train_AverageReturn : -39.596160888671875
Train_StdReturn : 32.045989990234375
Train_MaxReturn : -8.489358901977539
Train_MinReturn : -147.63780212402344
Train_AverageEpLen : 37.407407407407405
Train_EnvstepsSoFar : 12223
TimeSinceStart : 214.05404448509216
Training Loss : 0.4178837239742279
Initial_DataCollection_AverageReturn : -163.6405487060547
Done logging...




********** Iteration 8 ************

Collecting data to be used for training...
At timestep:     44 / 1000At timestep:    /home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/spaces/box.py:128: UserWarning: [33mWARN: Box bound precision lowered by casting to float32[0m
  logger.warn(f"Box bound precision lowered by casting to {self.dtype}")
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:191: UserWarning: [33mWARN: Future gym versions will require that `Env.reset` can be passed `return_info` to return information from the environment resetting.[0m
  "Future gym versions will require that `Env.reset` can be passed `return_info` to return information from the environment resetting."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:196: UserWarning: [33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.[0m
  "Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:142: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64[0m
  f"{pre} was expecting numpy array dtype to be {observation_space.dtype}, actual type: {obs.dtype}"
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: [33mWARN: The obs returned by the `reset()` method is not within the observation space.[0m
  logger.warn(f"{pre} is not within the observation space.")
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  "Core environment is written in old step API which returns one bool instead of two. "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:235: UserWarning: [33mWARN: Expects `done` signal to be a boolean, actual type: <class 'numpy.float64'>[0m
  f"Expects `done` signal to be a boolean, actual type: {type(done)}"
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:142: UserWarning: [33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: float64[0m
  f"{pre} was expecting numpy array dtype to be {observation_space.dtype}, actual type: {obs.dtype}"
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: [33mWARN: The obs returned by the `step()` method is not within the observation space.[0m
  logger.warn(f"{pre} is not within the observation space.")
 95 / 1000At timestep:     128 / 1000At timestep:     156 / 1000At timestep:     175 / 1000At timestep:     216 / 1000At timestep:     237 / 1000At timestep:     255 / 1000At timestep:     281 / 1000At timestep:     300 / 1000At timestep:     319 / 1000At timestep:     340 / 1000At timestep:     381 / 1000At timestep:     403 / 1000At timestep:     436 / 1000At timestep:     470 / 1000At timestep:     505 / 1000At timestep:     531 / 1000At timestep:     580 / 1000At timestep:     595 / 1000At timestep:     613 / 1000At timestep:     635 / 1000At timestep:     666 / 1000At timestep:     686 / 1000At timestep:     740 / 1000At timestep:     762 / 1000At timestep:     795 / 1000At timestep:     817 / 1000At timestep:     879 / 1000At timestep:     898 / 1000At timestep:     940 / 1000At timestep:     958 / 1000At timestep:     979 / 1000At timestep:     1001 / 1000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     16 / 400At timestep:     44 / 400At timestep:     72 / 400At timestep:     89 / 400At timestep:     113 / 400At timestep:     148 / 400At timestep:     175 / 400At timestep:     193 / 400At timestep:     213 / 400At timestep:     240 / 400At timestep:     266 / 400At timestep:     292 / 400At timestep:     344 / 400At timestep:     364 / 400At timestep:     390 / 400At timestep:     410 / 400Eval_AverageReturn : -22.16809844970703
Eval_StdReturn : 14.804327964782715
Eval_MaxReturn : -9.784408569335938
Eval_MinReturn : -75.53021240234375
Eval_AverageEpLen : 25.625
Train_AverageReturn : -28.869924545288086
Train_StdReturn : 18.033903121948242
Train_MaxReturn : -9.085773468017578
Train_MinReturn : -73.11389923095703
Train_AverageEpLen : 29.441176470588236
Train_EnvstepsSoFar : 13224
TimeSinceStart : 242.7623052597046
Training Loss : 0.41433966159820557
Initial_DataCollection_AverageReturn : -163.6405487060547
Done logging...




********** Iteration 9 ************

Collecting data to be used for training...
At timestep:     19 / 1000At timestep:     46 / 1000At timestep:     76 / 1000At timestep:     108 / 1000At timestep:     133 / 1000At timestep:     151 / 1000At timestep:     167 / 1000At timestep:     183 / 1000At timestep:     203 / 1000At timestep:     227 / 1000At timestep:     252 / 1000At timestep:     271 / 1000At timestep:     288 / 1000At timestep:     309 / 1000At timestep:     335 / 1000At timestep:     350 / 1000At timestep:     381 / 1000At timestep:     403 / 1000At timestep:     427 / 1000At timestep:     445 / 1000At timestep:     467 / 1000At timestep:     499 / 1000At timestep:     518 / 1000At timestep:     547 / 1000At timestep:     573 / 1000At timestep:     598 / 1000At timestep:     615 / 1000At timestep:     668 / 1000At timestep:     708 / 1000At timestep:     741 / 1000At timestep:     783 / 1000At timestep:     882 / 1000At timestep:     924 / 1000At timestep:     945 / 1000At timestep:     970 / 1000At timestep:     994 / 1000At timestep:     1017 / 1000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     31 / 400At timestep:     58 / 400At timestep:     86 / 400At timestep:     116 / 400At timestep:     134 / 400At timestep:     158 / 400At timestep:     181 / 400At timestep:     219 / 400At timestep:     320 / 400At timestep:     351 / 400At timestep:     373 / 400At timestep:     389 / 400At timestep:     425 / 400Eval_AverageReturn : -36.426109313964844
Eval_StdReturn : 39.40607452392578
Eval_MaxReturn : -10.757561683654785
Eval_MinReturn : -168.7849884033203
Eval_AverageEpLen : 32.69230769230769
Train_AverageReturn : -27.2613582611084
Train_StdReturn : 25.32721519470215
Train_MaxReturn : -8.65611743927002
Train_MinReturn : -160.64520263671875
Train_AverageEpLen : 27.486486486486488
Train_EnvstepsSoFar : 14241
TimeSinceStart : 272.2807466983795
Training Loss : 0.4001959264278412
Initial_DataCollection_AverageReturn : -163.6405487060547
Done logging...




********** Iteration 10 ************

Collecting data to be used for training...
At timestep:     17 / 1000At timestep:     32 / 1000At timestep:     63 / 1000At timestep:     84 / 1000At timestep:     102 / 1000At timestep:     128 / 1000At timestep:     198 / 1000At timestep:     218 / 1000At timestep:     252 / 1000At timestep:     281 / 1000At timestep:     302 / 1000At timestep:     332 / 1000At timestep:     352 / 1000At timestep:     376 / 1000At timestep:     445 / 1000At timestep:     467 / 1000At timestep:     492 / 1000At timestep:     516 / 1000At timestep:     545 / 1000At timestep:     572 / 1000At timestep:     593 / 1000At timestep:     611 / 1000At timestep:     631 / 1000At timestep:     664 / 1000At timestep:     691 / 1000At timestep:     711 / 1000At timestep:     754 / 1000At timestep:     783 / 1000At timestep:     840 / 1000At timestep:     857 / 1000At timestep:     885 / 1000At timestep:     931 / 1000At timestep:     955 / 1000At timestep:     1010 / 1000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     22 / 400At timestep:     47 / 400At timestep:     76 / 400At timestep:     103 / 400At timestep:     146 / 400At timestep:     166 / 400At timestep:     192 / 400At timestep:     224 / 400At timestep:     255 / 400At timestep:     278 / 400At timestep:     307 / 400At timestep:     350 / 400At timestep:     366 / 400At timestep:     395 / 400At timestep:     412 / 400Eval_AverageReturn : -26.7607364654541
Eval_StdReturn : 12.489225387573242
Eval_MaxReturn : -12.256064414978027
Eval_MinReturn : -58.77938461303711
Eval_AverageEpLen : 27.466666666666665
Train_AverageReturn : -30.347021102905273
Train_StdReturn : 20.668176651000977
Train_MaxReturn : -9.470983505249023
Train_MinReturn : -102.50846099853516
Train_AverageEpLen : 29.705882352941178
Train_EnvstepsSoFar : 15251
TimeSinceStart : 301.4184241294861
Training Loss : 0.4043246805667877
Initial_DataCollection_AverageReturn : -163.6405487060547
Done logging...




********** Iteration 11 ************

Collecting data to be used for training...
At timestep:     48 / 1000At timestep:     67 / 1000At timestep:     85 / 1000At timestep:     141 / 1000At timestep:     159 / 1000At timestep:     188 / 1000At timestep:     218 / 1000At timestep:     246 / 1000At timestep:     273 / 1000At timestep:     295 / 1000At timestep:     321 / 1000At timestep:     349 / 1000At timestep:     376 / 1000At timestep:     398 / 1000At timestep:     446 / 1000At timestep:     482 / 1000At timestep:     501 / 1000At timestep:     527 / 1000At timestep:     543 / 1000At timestep:     557 / 1000At timestep:     604 / 1000At timestep:     622 / 1000At timestep:     651 / 1000At timestep:     686 / 1000At timestep:     704 / 1000At timestep:     734 / 1000At timestep:     757 / 1000At timestep:     774 / 1000At timestep:     810 / 1000At timestep:     825 / 1000At timestep:     848 / 1000At timestep:     939 / 1000At timestep:     958 / 1000At timestep:     1052 / 1000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     21 / 400At timestep:     45 / 400At timestep:     68 / 400At timestep:     87 / 400At timestep:     107 / 400At timestep:     151 / 400At timestep:     240 / 400At timestep:     276 / 400At timestep:     297 / 400At timestep:     322 / 400At timestep:     339 / 400At timestep:     362 / 400At timestep:     386 / 400At timestep:     411 / 400Eval_AverageReturn : -30.00228500366211
Eval_StdReturn : 31.989564895629883
Eval_MaxReturn : -12.322982788085938
Eval_MinReturn : -138.97537231445312
Eval_AverageEpLen : 29.357142857142858
Train_AverageReturn : -31.14488983154297
Train_StdReturn : 28.118694305419922
Train_MaxReturn : -7.88134241104126
Train_MinReturn : -145.6745147705078
Train_AverageEpLen : 30.941176470588236
Train_EnvstepsSoFar : 16303
TimeSinceStart : 331.68700551986694
Training Loss : 0.3992149829864502
Initial_DataCollection_AverageReturn : -163.6405487060547
Done logging...





LOGGING TO:  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q3_reacher_reacher-cs285-v0_02-11-2022_00-37-33 



########################
logging outputs to  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q3_reacher_reacher-cs285-v0_02-11-2022_00-37-33
########################
Using GPU id 0
Using action sampling strategy: random


********** Iteration 0 ************

Collecting data to be used for training...
At timestep:     201 / 5000At timestep:     402 / 5000At timestep:     603 / 5000At timestep:     804 / 5000At timestep:     1005 / 5000At timestep:     1206 / 5000At timestep:     1407 / 5000At timestep:     1608 / 5000At timestep:     1809 / 5000At timestep:     2010 / 5000At timestep:     2211 / 5000At timestep:     2412 / 5000At timestep:     2613 / 5000At timestep:     2814 / 5000At timestep:     3015 / 5000At timestep:     3216 / 5000At timestep:     3417 / 5000At timestep:     3618 / 5000At timestep:     3819 / 5000At timestep:     4020 / 5000At timestep:     4221 / 5000At timestep:     4422 / 5000At timestep:     4623 / 5000At timestep:     4824 / 5000At timestep:     5025 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -613.611328125
Eval_StdReturn : 75.8062744140625
Eval_MaxReturn : -537.8050537109375
Eval_MinReturn : -689.4176025390625
Eval_AverageEpLen : 201.0
Train_AverageReturn : -1860.1959228515625
Train_StdReturn : 332.0581970214844
Train_MaxReturn : -1283.0159912109375
Train_MinReturn : -2515.0615234375
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 5025
TimeSinceStart : 16.90107297897339
Training Loss : 0.15316544473171234
Initial_DataCollection_AverageReturn : -1860.1959228515625
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...
At timestep:     201 / 5000At timestep:     402 / 5000At timestep:     603 / 5000At timestep:     804 / 5000At timestep:     1005 / 5000At timestep:     1206 / 5000At timestep:     1407 / 5000At timestep:     1608 / 5000At timestep:     1809 / 5000At timestep:     2010 / 5000At timestep:     2211 / 5000At timestep:     2412 / 5000At timestep:     2613 / 5000At timestep:     2814 / 5000At timestep:     3015 / 5000At timestep:     3216 / 5000At timestep:     3417 / 5000At timestep:     3618 / 5000At timestep:     3819 / 5000At timestep:     4020 / 5000At timestep:     4221 / 5000At timestep:     4422 / 5000At timestep:     4623 / 5000At timestep:     4824 / 5000At timestep:     5025 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -340.05975341796875
Eval_StdReturn : 45.38523864746094
Eval_MaxReturn : -294.6745300292969
Eval_MinReturn : -385.44500732421875
Eval_AverageEpLen : 201.0
Train_AverageReturn : -628.8524780273438
Train_StdReturn : 141.54942321777344
Train_MaxReturn : -318.8472595214844
Train_MinReturn : -923.3856811523438
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 10050
TimeSinceStart : 139.67650294303894
Training Loss : 0.1646980494260788
Initial_DataCollection_AverageReturn : -1860.1959228515625
Done logging...




********** Iteration 2 ************

Collecting data to be used for training...
At timestep:     201 / 5000At timestep:     402 / 5000At timestep:     603 / 5000At timestep:     804 / 5000At timestep:     1005 / 5000At timestep:     1206 / 5000At timestep:     1407 / 5000At timestep:     1608 / 5000At timestep:     1809 / 5000At timestep:     2010 / 5000At timestep:     2211 / 5000At timestep:     2412 / 5000At timestep:     2613 / 5000At timestep:     2814 / 5000At timestep:     3015 / 5000At timestep:     3216 / 5000At timestep:     3417 / 5000At timestep:     3618 / 5000At timestep:     3819 / 5000At timestep:     4020 / 5000At timestep:     4221 / 5000At timestep:     4422 / 5000At timestep:     4623 / 5000At timestep:     4824 / 5000At timestep:     5025 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -282.3158874511719
Eval_StdReturn : 28.792266845703125
Eval_MaxReturn : -253.52362060546875
Eval_MinReturn : -311.108154296875
Eval_AverageEpLen : 201.0
Train_AverageReturn : -413.6169128417969
Train_StdReturn : 80.37649536132812
Train_MaxReturn : -262.5813903808594
Train_MinReturn : -643.66064453125
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 15075
TimeSinceStart : 263.3779716491699
Training Loss : 0.16290943324565887
Initial_DataCollection_AverageReturn : -1860.1959228515625
Done logging...




********** Iteration 3 ************

Collecting data to be used for training...
At timestep:     201 / 5000At timestep:     402 / 5000At timestep:     603 / 5000At timestep:     804 / 5000At timestep:     1005 / 5000At timestep:     1206 / 5000At timestep:     1407 / 5000At timestep:     1608 / 5000At timestep:     1809 / 5000At timestep:     2010 / 5000At timestep:     2211 / 5000At timestep:     2412 / 5000At timestep:     2613 / 5000At timestep:     2814 / 5000At timestep:     3015 / 5000At timestep:     3216 / 5000At timestep:     3417 / 5000At timestep:     3618 / 5000At timestep:     3819 / 5000At timestep:     4020 / 5000At timestep:     4221 / 5000At timestep:     4422 / 5000At timestep:     4623 / 5000At timestep:     4824 / 5000At timestep:     5025 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -293.21209716796875
Eval_StdReturn : 22.850753784179688
Eval_MaxReturn : -270.361328125
Eval_MinReturn : -316.0628356933594
Eval_AverageEpLen : 201.0
Train_AverageReturn : -289.2962646484375
Train_StdReturn : 28.474014282226562
Train_MaxReturn : -255.68455505371094
Train_MinReturn : -353.6850891113281
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 20100
TimeSinceStart : 387.6696391105652
Training Loss : 0.15377207100391388
Initial_DataCollection_AverageReturn : -1860.1959228515625
Done logging...




********** Iteration 4 ************

Collecting data to be used for training...
At timestep:     201 / 5000At timestep:     402 / 5000At timestep:     603 / 5000At timestep:     804 / 5000At timestep:     1005 / 5000At timestep:     1206 / 5000At timestep:     1407 / 5000At timestep:     1608 / 5000At timestep:     1809 / 5000At timestep:     2010 / 5000At timestep:     2211 / 5000At timestep:     2412 / 5000At timestep:     2613 / 5000At timestep:     2814 / 5000At timestep:     3015 / 5000At timestep:     3216 / 5000At timestep:     3417 / 5000At timestep:     3618 / 5000At timestep:     3819 / 5000At timestep:     4020 / 5000At timestep:     4221 / 5000At timestep:     4422 / 5000At timestep:     4623 / 5000At timestep:     4824 / 5000At timestep:     5025 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -253.99696350097656
Eval_StdReturn : 12.350875854492188
Eval_MaxReturn : -241.64608764648438
Eval_MinReturn : -266.34783935546875
Eval_AverageEpLen : 201.0
Train_AverageReturn : -280.0067443847656
Train_StdReturn : 26.101871490478516
Train_MaxReturn : -241.72874450683594
Train_MinReturn : -329.1400146484375
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 25125
TimeSinceStart : 512.888341665268
Training Loss : 0.15225128829479218
Initial_DataCollection_AverageReturn : -1860.1959228515625
Done logging...




********** Iteration 5 ************

Collecting data to be used for training...
At timestep:     201 / 5000At timestep:     402 / 5000At timestep:     603 / 5000At timestep:     804 / 5000At timestep:     1005 / 5000At timestep:     1206 / 5000At timestep:     1407 / 5000At timestep:     1608 / 5000At timestep:     1809 / 5000At timestep:     2010 / 5000At timestep:     2211 / 5000At timestep:     2412 / 5000At timestep:     2613 / 5000At timestep:     2814 / 5000At timestep:     3015 / 5000At timestep:     3216 / 5000At timestep:     3417 / 5000At timestep:     3618 / 5000At timestep:     3819 / 5000At timestep:     4020 / 5000At timestep:     4221 / 5000At timestep:     4422 / 5000At timestep:     4623 / 5000At timestep:     4824 / 5000At timestep:     5025 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -274.1679382324219
Eval_StdReturn : 19.310943603515625
Eval_MaxReturn : -254.85699462890625
Eval_MinReturn : -293.4788818359375
Eval_AverageEpLen : 201.0
Train_AverageReturn : -266.9260559082031
Train_StdReturn : 19.632898330688477
Train_MaxReturn : -229.45431518554688
Train_MinReturn : -324.0931701660156
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 30150
TimeSinceStart : 638.3273067474365
Training Loss : 0.14500278234481812
Initial_DataCollection_AverageReturn : -1860.1959228515625
Done logging...




********** Iteration 6 ************

Collecting data to be used for training...
At timestep:     201 / 5000At timestep:     402 / 5000At timestep:     603 / 5000At timestep:     804 / 5000At timestep:     1005 / 5000At timestep:     1206 / 5000At timestep:     1407 / 5000At timestep:     1608 / 5000At timestep:     1809 / 5000At timestep:     2010 / 5000At timestep:     2211 / 5000At timestep:     2412 / 5000At timestep:     2613 / 5000At timestep:     2814 / 5000At timestep:     3015 / 5000At timestep:     3216 / 5000At timestep:     3417 / 5000At timestep:     3618 / 5000At timestep:     3819 / 5000At timestep:     4020 / 5000At timestep:     4221 / 5000At timestep:     4422 / 5000At timestep:     4623 / 5000At timestep:     4824 / 5000At timestep:     5025 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -285.8308410644531
Eval_StdReturn : 3.425048828125
Eval_MaxReturn : -282.4057922363281
Eval_MinReturn : -289.2558898925781
Eval_AverageEpLen : 201.0
Train_AverageReturn : -265.4612121582031
Train_StdReturn : 15.853348731994629
Train_MaxReturn : -242.3197021484375
Train_MinReturn : -309.950439453125
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 35175
TimeSinceStart : 763.7528493404388
Training Loss : 0.14620576798915863
Initial_DataCollection_AverageReturn : -1860.1959228515625
Done logging...




********** Iteration 7 ************

Collecting data to be used for training...
At timestep:     201 / 5000At timestep:     402 / 5000At timestep:     603 / 5000At timestep:     804 / 5000At timestep:     1005 / 5000At timestep:     1206 / 5000At timestep:     1407 / 5000At timestep:     1608 / 5000At timestep:     1809 / 5000At timestep:     2010 / 5000At timestep:     2211 / 5000At timestep:     2412 / 5000At timestep:     2613 / 5000At timestep:     2814 / 5000At timestep:     3015 / 5000At timestep:     3216 / 5000At timestep:     3417 / 5000At timestep:     3618 / 5000At timestep:     3819 / 5000At timestep:     4020 / 5000At timestep:     4221 / 5000At timestep:     4422 / 5000At timestep:     4623 / 5000At timestep:     4824 / 5000At timestep:     5025 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -278.5768127441406
Eval_StdReturn : 31.19896697998047
Eval_MaxReturn : -247.3778533935547
Eval_MinReturn : -309.7757873535156
Eval_AverageEpLen : 201.0
Train_AverageReturn : -268.2618713378906
Train_StdReturn : 18.323017120361328
Train_MaxReturn : -229.2379608154297
Train_MinReturn : -315.7669677734375
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 40200
TimeSinceStart : 889.0587408542633
Training Loss : 0.14493882656097412
Initial_DataCollection_AverageReturn : -1860.1959228515625
Done logging...




********** Iteration 8 ************

Collecting data to be used for training...
At timestep:     201 / 5000At timestep:     402 / 5000At timestep:     603 / 5000At timestep:     804 / 5000At timestep:     1005 / 5000At timestep:     1206 / 5000At timestep:     1407 / 5000At timestep:     1608 / 5000At timestep:     1809 / 5000At timestep:     2010 / 5000At timestep:     2211 / 5000At timestep:     2412 / 5000At timestep:     2613 / 5000At timestep:     2814 / 5000At timestep:     3015 / 5000At timestep:     3216 / 5000At timestep:     3417 / 5000At timestep:     3618 / 5000At timestep:     3819 / 5000At timestep:     4020 / 5000At timestep:     4221 / 5000At timestep:     4422 / 5000At timestep:     4623 / 5000At timestep:     4824 / 5000At timestep:     5025 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -258.36492919921875
Eval_StdReturn : 16.65540313720703
Eval_MaxReturn : -241.7095184326172
Eval_MinReturn : -275.02032470703125
Eval_AverageEpLen : 201.0
Train_AverageReturn : -267.5899353027344
Train_StdReturn : 13.01325511932373
Train_MaxReturn : -237.25381469726562
Train_MinReturn : -291.397216796875
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 45225
TimeSinceStart : 1014.8368320465088
Training Loss : 0.14227251708507538
Initial_DataCollection_AverageReturn : -1860.1959228515625
Done logging...




********** Iteration 9 ************

Collecting data to be used for training...
At timestep:     201 / 5000At timestep:     402 / 5000At timestep:     603 / 5000At timestep:     804 / 5000At timestep:     1005 / 5000At timestep:     1206 / 5000At timestep:     1407 / 5000At timestep:     1608 / 5000At timestep:     1809 / 5000At timestep:     2010 / 5000At timestep:     2211 / 5000At timestep:     2412 / 5000At timestep:     2613 / 5000At timestep:     2814 / 5000At timestep:     3015 / 5000At timestep:     3216 / 5000At timestep:     3417 / 5000At timestep:     3618 / 5000At timestep:     3819 / 5000At timestep:     4020 / 5000At timestep:     4221 / 5000At timestep:     4422 / 5000At timestep:     4623 / 5000At timestep:     4824 / 5000At timestep:     5025 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -278.4981689453125
Eval_StdReturn : 11.23541259765625
Eval_MaxReturn : -267.26275634765625
Eval_MinReturn : -289.73358154296875
Eval_AverageEpLen : 201.0
Train_AverageReturn : -267.5994567871094
Train_StdReturn : 18.79411506652832
Train_MaxReturn : -237.81858825683594
Train_MinReturn : -307.2959289550781
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 50250
TimeSinceStart : 1142.5049057006836
Training Loss : 0.13967913389205933
Initial_DataCollection_AverageReturn : -1860.1959228515625
Done logging...




********** Iteration 10 ************

Collecting data to be used for training...
At timestep:     201 / 5000At timestep:     402 / 5000At timestep:     603 / 5000At timestep:     804 / 5000At timestep:     1005 / 5000At timestep:     1206 / 5000At timestep:     1407 / 5000At timestep:     1608 / 5000At timestep:     1809 / 5000At timestep:     2010 / 5000At timestep:     2211 / 5000At timestep:     2412 / 5000At timestep:     2613 / 5000At timestep:     2814 / 5000At timestep:     3015 / 5000At timestep:     3216 / 5000At timestep:     3417 / 5000At timestep:     3618 / 5000At timestep:     3819 / 5000At timestep:     4020 / 5000At timestep:     4221 / 5000At timestep:     4422 / 5000At timestep:     4623 / 5000At timestep:     4824 / 5000At timestep:     5025 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -264.20367431640625
Eval_StdReturn : 2.4587554931640625
Eval_MaxReturn : -261.7449035644531
Eval_MinReturn : -266.66241455078125
Eval_AverageEpLen : 201.0
Train_AverageReturn : -273.86004638671875
Train_StdReturn : 15.400333404541016
Train_MaxReturn : -245.9031524658203
Train_MinReturn : -309.3468322753906
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 55275
TimeSinceStart : 1267.4038701057434/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/core.py:257: DeprecationWarning: [33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.[0m
  "Function `env.seed(seed)` is marked as deprecated and will be removed in the future. "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  "Core environment is written in old step API which returns one bool instead of two. "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:235: UserWarning: [33mWARN: Expects `done` signal to be a boolean, actual type: <class 'numpy.float64'>[0m
  f"Expects `done` signal to be a boolean, actual type: {type(done)}"

Training Loss : 0.13631494343280792
Initial_DataCollection_AverageReturn : -1860.1959228515625
Done logging...




********** Iteration 11 ************

Collecting data to be used for training...
At timestep:     201 / 5000At timestep:     402 / 5000At timestep:     603 / 5000At timestep:     804 / 5000At timestep:     1005 / 5000At timestep:     1206 / 5000At timestep:     1407 / 5000At timestep:     1608 / 5000At timestep:     1809 / 5000At timestep:     2010 / 5000At timestep:     2211 / 5000At timestep:     2412 / 5000At timestep:     2613 / 5000At timestep:     2814 / 5000At timestep:     3015 / 5000At timestep:     3216 / 5000At timestep:     3417 / 5000At timestep:     3618 / 5000At timestep:     3819 / 5000At timestep:     4020 / 5000At timestep:     4221 / 5000At timestep:     4422 / 5000At timestep:     4623 / 5000At timestep:     4824 / 5000At timestep:     5025 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -253.69515991210938
Eval_StdReturn : 11.714912414550781
Eval_MaxReturn : -241.98023986816406
Eval_MinReturn : -265.4100646972656
Eval_AverageEpLen : 201.0
Train_AverageReturn : -258.1202087402344
Train_StdReturn : 13.897029876708984
Train_MaxReturn : -238.9853973388672
Train_MinReturn : -298.1895446777344
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 60300
TimeSinceStart : 1392.3770034313202
Training Loss : 0.13677959144115448
Initial_DataCollection_AverageReturn : -1860.1959228515625
Done logging...




********** Iteration 12 ************

Collecting data to be used for training...
At timestep:     201 / 5000At timestep:     402 / 5000At timestep:     603 / 5000At timestep:     804 / 5000At timestep:     1005 / 5000At timestep:     1206 / 5000At timestep:     1407 / 5000At timestep:     1608 / 5000At timestep:     1809 / 5000At timestep:     2010 / 5000At timestep:     2211 / 5000At timestep:     2412 / 5000At timestep:     2613 / 5000At timestep:     2814 / 5000At timestep:     3015 / 5000At timestep:     3216 / 5000At timestep:     3417 / 5000At timestep:     3618 / 5000At timestep:     3819 / 5000At timestep:     4020 / 5000At timestep:     4221 / 5000At timestep:     4422 / 5000At timestep:     4623 / 5000At timestep:     4824 / 5000At timestep:     5025 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -258.42279052734375
Eval_StdReturn : 3.3522567749023438
Eval_MaxReturn : -255.07054138183594
Eval_MinReturn : -261.7750549316406
Eval_AverageEpLen : 201.0
Train_AverageReturn : -266.0733642578125
Train_StdReturn : 15.471962928771973
Train_MaxReturn : -238.20904541015625
Train_MinReturn : -305.018310546875
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 65325
TimeSinceStart : 1517.0996088981628
Training Loss : 0.13037216663360596
Initial_DataCollection_AverageReturn : -1860.1959228515625
Done logging...




********** Iteration 13 ************

Collecting data to be used for training...
At timestep:     201 / 5000At timestep:     402 / 5000At timestep:     603 / 5000At timestep:     804 / 5000At timestep:     1005 / 5000At timestep:     1206 / 5000At timestep:     1407 / 5000At timestep:     1608 / 5000At timestep:     1809 / 5000At timestep:     2010 / 5000At timestep:     2211 / 5000At timestep:     2412 / 5000At timestep:     2613 / 5000At timestep:     2814 / 5000At timestep:     3015 / 5000At timestep:     3216 / 5000At timestep:     3417 / 5000At timestep:     3618 / 5000At timestep:     3819 / 5000At timestep:     4020 / 5000At timestep:     4221 / 5000At timestep:     4422 / 5000At timestep:     4623 / 5000At timestep:     4824 / 5000At timestep:     5025 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -257.3997802734375
Eval_StdReturn : 1.2160797119140625
Eval_MaxReturn : -256.1836853027344
Eval_MinReturn : -258.6158447265625
Eval_AverageEpLen : 201.0
Train_AverageReturn : -267.6744689941406
Train_StdReturn : 15.438093185424805
Train_MaxReturn : -236.30796813964844
Train_MinReturn : -301.8098449707031
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 70350
TimeSinceStart : 1641.7693700790405
Training Loss : 0.1276894360780716
Initial_DataCollection_AverageReturn : -1860.1959228515625
Done logging...




********** Iteration 14 ************

Collecting data to be used for training...
At timestep:     201 / 5000At timestep:     402 / 5000At timestep:     603 / 5000At timestep:     804 / 5000At timestep:     1005 / 5000At timestep:     1206 / 5000At timestep:     1407 / 5000At timestep:     1608 / 5000At timestep:     1809 / 5000At timestep:     2010 / 5000At timestep:     2211 / 5000At timestep:     2412 / 5000At timestep:     2613 / 5000At timestep:     2814 / 5000At timestep:     3015 / 5000At timestep:     3216 / 5000At timestep:     3417 / 5000At timestep:     3618 / 5000At timestep:     3819 / 5000At timestep:     4020 / 5000At timestep:     4221 / 5000At timestep:     4422 / 5000At timestep:     4623 / 5000At timestep:     4824 / 5000At timestep:     5025 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -275.755126953125
Eval_StdReturn : 5.7411651611328125
Eval_MaxReturn : -270.01397705078125
Eval_MinReturn : -281.4963073730469
Eval_AverageEpLen : 201.0
Train_AverageReturn : -262.195068359375
Train_StdReturn : 14.962949752807617
Train_MaxReturn : -239.66856384277344
Train_MinReturn : -287.4671325683594
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 75375
TimeSinceStart : 1766.817437171936
Training Loss : 0.1279062181711197
Initial_DataCollection_AverageReturn : -1860.1959228515625
Done logging...





LOGGING TO:  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q3_cheetah_cheetah-cs285-v0_02-11-2022_01-07-04 



########################
logging outputs to  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q3_cheetah_cheetah-cs285-v0_02-11-2022_01-07-04
########################
Using GPU id 0
Using action sampling strategy: random


********** Iteration 0 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 89.53544616699219
Eval_StdReturn : 0.0
Eval_MaxReturn : 89.53544616699219
Eval_MinReturn : 89.53544616699219
Eval_AverageEpLen : 501.0
Train_AverageReturn : -2501.908447265625
Train_StdReturn : 326.896728515625
Train_MaxReturn : -2060.5048828125
Train_MinReturn : -3182.69873046875
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 5010
TimeSinceStart : 26.68984317779541
Training Loss : 0.07185449451208115
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 178.63790893554688
Eval_StdReturn : 0.0
Eval_MaxReturn : 178.63790893554688
Eval_MinReturn : 178.63790893554688
Eval_AverageEpLen : 501.0
Train_AverageReturn : 96.09175872802734
Train_StdReturn : 24.808679580688477
Train_MaxReturn : 147.76097106933594
Train_MinReturn : 60.023040771484375
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 10020
TimeSinceStart : 212.09101057052612
Training Loss : 0.09188862890005112
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 2 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 216.36093139648438
Eval_StdReturn : 0.0
Eval_MaxReturn : 216.36093139648438
Eval_MinReturn : 216.36093139648438
Eval_AverageEpLen : 501.0
Train_AverageReturn : 213.2714080810547
Train_StdReturn : 33.82615661621094
Train_MaxReturn : 275.7296142578125
Train_MinReturn : 141.15255737304688
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 15030
TimeSinceStart : 398.05926156044006
Training Loss : 0.09902621060609818
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 3 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 232.41098022460938
Eval_StdReturn : 0.0
Eval_MaxReturn : 232.41098022460938
Eval_MinReturn : 232.41098022460938
Eval_AverageEpLen : 501.0
Train_AverageReturn : 267.5205383300781
Train_StdReturn : 18.24093246459961
Train_MaxReturn : 294.0146484375
Train_MinReturn : 234.6994171142578
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 20040
TimeSinceStart : 584.6309242248535
Training Loss : 0.10201562196016312
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 4 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 346.83935546875
Eval_StdReturn : 0.0
Eval_MaxReturn : 346.83935546875
Eval_MinReturn : 346.83935546875
Eval_AverageEpLen : 501.0
Train_AverageReturn : 252.77066040039062
Train_StdReturn : 32.60719299316406
Train_MaxReturn : 315.83917236328125
Train_MinReturn : 207.86936950683594
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 25050
TimeSinceStart : 771.1944262981415
Training Loss : 0.09776756167411804
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 5 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 322.1243591308594
Eval_StdReturn : 0.0
Eval_MaxReturn : 322.1243591308594
Eval_MinReturn : 322.1243591308594
Eval_AverageEpLen : 501.0
Train_AverageReturn : 258.4477844238281
Train_StdReturn : 33.407859802246094
Train_MaxReturn : 312.18402099609375
Train_MinReturn : 219.04342651367188
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 30060
TimeSinceStart : 957.5270433425903
Training Loss : 0.10094697028398514
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 6 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 200.40097045898438
Eval_StdReturn : 0.0
Eval_MaxReturn : 200.40097045898438
Eval_MinReturn : 200.40097045898438
Eval_AverageEpLen : 501.0
Train_AverageReturn : 262.020263671875
Train_StdReturn : 40.58882522583008
Train_MaxReturn : 343.4887390136719
Train_MinReturn : 220.31283569335938
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 35070
TimeSinceStart : 1144.295803308487
Training Loss : 0.10591208934783936
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 7 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 259.984619140625
Eval_StdReturn : 0.0
Eval_MaxReturn : 259.984619140625
Eval_MinReturn : 259.984619140625
Eval_AverageEpLen : 501.0
Train_AverageReturn : 283.2737731933594
Train_StdReturn : 38.29103469848633
Train_MaxReturn : 344.1591491699219
Train_MinReturn : 227.04725646972656
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 40080
TimeSinceStart : 1330.3955810070038
Training Loss : 0.10483687371015549
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 8 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 308.8607482910156
Eval_StdReturn : 0.0
Eval_MaxReturn : 308.8607482910156
Eval_MinReturn : 308.8607482910156
Eval_AverageEpLen : 501.0
Train_AverageReturn : 289.35528564453125
Train_StdReturn : 44.04341506958008
Train_MaxReturn : 351.14593505859375
Train_MinReturn : 179.9693603515625
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 45090
TimeSinceStart : 1516.1830716133118
Training Loss : 0.10535339266061783
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 9 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 285.71990966796875
Eval_StdReturn : 0.0
Eval_MaxReturn : 285.71990966796875
Eval_MinReturn : 285.71990966796875
Eval_AverageEpLen : 501.0
Train_AverageReturn : 305.96771240234375
Train_StdReturn : 37.45865249633789
Train_MaxReturn : 368.7496337890625
Train_MinReturn : 216.87936401367188
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 50100
TimeSinceStart : 1700.704064130783
Training Loss : 0.10768672078847885
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 10 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 278.6365966796875
Eval_StdReturn : 0.0
Eval_MaxReturn : 278.6365966796875
Eval_MinReturn : 278.6365966796875
Eval_AverageEpLen : 501.0
Train_AverageReturn : 311.8534240722656
Train_StdReturn : 32.59304428100586
Train_MaxReturn : 379.94793701171875
Train_MinReturn : 268.46624755859375
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 55110
TimeSinceStart : 1885.6097271442413
Training Loss : 0.1043381467461586
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 11 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 305.6990661621094
Eval_StdReturn : 0.0
Eval_MaxReturn : 305.6990661621094
Eval_MinReturn : 305.6990661621094
Eval_AverageEpLen : 501.0
Train_AverageReturn : 306.87115478515625
Train_StdReturn : 33.9593505859375
Train_MaxReturn : 374.1429443359375
Train_MinReturn : 260.8482666015625
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 60120
TimeSinceStart : 2072.23584651947
Training Loss : 0.10404375940561295
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 12 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 284.4078369140625
Eval_StdReturn : 0.0
Eval_MaxReturn : 284.4078369140625
Eval_MinReturn : 284.4078369140625
Eval_AverageEpLen : 501.0
Train_AverageReturn : 283.1651916503906
Train_StdReturn : 39.36116409301758
Train_MaxReturn : 345.58331298828125
Train_MinReturn : 225.3140869140625
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 65130
TimeSinceStart : 2256.674397468567
Training Loss : 0.10565600544214249
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 13 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 241.16641235351562
Eval_StdReturn : 0.0
Eval_MaxReturn : 241.16641235351562
Eval_MinReturn : 241.16641235351562
Eval_AverageEpLen : 501.0
Train_AverageReturn : 289.6659240722656
Train_StdReturn : 28.22742462158203
Train_MaxReturn : 344.1971435546875
Train_MinReturn : 239.92063903808594
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 70140
TimeSinceStart : 2440.7989909648895
Training Loss : 0.10579221695661545
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 14 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 297.77862548828125
Eval_StdReturn : 0.0
Eval_MaxReturn : 297.77862548828125
Eval_MinReturn : 297.77862548828125
Eval_AverageEpLen : 501.0
Train_AverageReturn : 288.28363037109375
Train_StdReturn : 62.172332763671875
Train_MaxReturn : 358.9265441894531
Train_MinReturn : 164.2388916015625
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 75150
TimeSinceStart : 2625.097084760666
Training Loss : 0.1035582646727562
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 15 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 291.0489501953125
Eval_StdReturn : 0.0
Eval_MaxReturn : 291.0489501953125
Eval_MinReturn : 291.0489501953125
Eval_AverageEpLen : 501.0
Train_AverageReturn : 323.21710205078125
Train_StdReturn : 21.899436950683594
Train_MaxReturn : 362.273681640625
Train_MinReturn : 282.78179931640625
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 80160
TimeSinceStart : 2809.6905517578125
Training Loss : 0.10537565499544144
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 16 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/core.py:257: DeprecationWarning: [33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.[0m
  "Function `env.seed(seed)` is marked as deprecated and will be removed in the future. "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/seeding.py:54: DeprecationWarning: [33mWARN: Function `rng.randn(*size)` is marked as deprecated and will be removed in the future. Please use `rng.standard_normal(size)` instead.[0m
  "Function `rng.randn(*size)` is marked as deprecated "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  "Core environment is written in old step API which returns one bool instead of two. "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:235: UserWarning: [33mWARN: Expects `done` signal to be a boolean, actual type: <class 'numpy.float64'>[0m
  f"Expects `done` signal to be a boolean, actual type: {type(done)}"
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/seeding.py:54: DeprecationWarning: [33mWARN: Function `rng.randn(*size)` is marked as deprecated and will be removed in the future. Please use `rng.standard_normal(size)` instead.[0m
  "Function `rng.randn(*size)` is marked as deprecated "
 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 269.962646484375
Eval_StdReturn : 0.0
Eval_MaxReturn : 269.962646484375
Eval_MinReturn : 269.962646484375
Eval_AverageEpLen : 501.0
Train_AverageReturn : 300.6490478515625
Train_StdReturn : 50.595550537109375
Train_MaxReturn : 393.4892272949219
Train_MinReturn : 225.09117126464844
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 85170
TimeSinceStart : 2993.7224910259247
Training Loss : 0.10423725843429565
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 17 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 383.809326171875
Eval_StdReturn : 0.0
Eval_MaxReturn : 383.809326171875
Eval_MinReturn : 383.809326171875
Eval_AverageEpLen : 501.0
Train_AverageReturn : 290.5040588378906
Train_StdReturn : 35.67810821533203
Train_MaxReturn : 370.8824462890625
Train_MinReturn : 250.3617706298828
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 90180
TimeSinceStart : 3178.0081765651703
Training Loss : 0.10514876246452332
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 18 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 371.86859130859375
Eval_StdReturn : 0.0
Eval_MaxReturn : 371.86859130859375
Eval_MinReturn : 371.86859130859375
Eval_AverageEpLen : 501.0
Train_AverageReturn : 313.6935119628906
Train_StdReturn : 48.928314208984375
Train_MaxReturn : 427.2140808105469
Train_MinReturn : 256.580322265625
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 95190
TimeSinceStart : 3362.7062277793884
Training Loss : 0.10361964255571365
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 19 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 345.8859558105469
Eval_StdReturn : 0.0
Eval_MaxReturn : 345.8859558105469
Eval_MinReturn : 345.8859558105469
Eval_AverageEpLen : 501.0
Train_AverageReturn : 345.33477783203125
Train_StdReturn : 44.093692779541016
Train_MaxReturn : 421.3613586425781
Train_MinReturn : 265.06732177734375
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 100200
TimeSinceStart : 3548.1037986278534
Training Loss : 0.10200505703687668
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...





LOGGING TO:  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q3_obstacles_obstacles-cs285-v0_02-11-2022_20-28-02 



########################
logging outputs to  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q3_obstacles_obstacles-cs285-v0_02-11-2022_20-28-02
########################
Using GPU id 0
Using action sampling strategy: random


********** Iteration 0 ************

Collecting data to be used for training...
At timestep:     101 / 5000At timestep:     202 / 5000At timestep:     303 / 5000At timestep:     404 / 5000At timestep:     505 / 5000At timestep:     606 / 5000At timestep:     707 / 5000At timestep:     808 / 5000At timestep:     909 / 5000At timestep:     1010 / 5000At timestep:     1111 / 5000At timestep:     1212 / 5000At timestep:     1313 / 5000At timestep:     1414 / 5000At timestep:     1515 / 5000At timestep:     1616 / 5000At timestep:     1717 / 5000At timestep:     1818 / 5000At timestep:     1919 / 5000At timestep:     2020 / 5000At timestep:     2121 / 5000At timestep:     2222 / 5000At timestep:     2323 / 5000At timestep:     2424 / 5000At timestep:     2525 / 5000At timestep:     2626 / 5000At timestep:     2727 / 5000At timestep:     2828 / 5000At timestep:     2929 / 5000At timestep:     3030 / 5000At timestep:     3131 / 5000At timestep:     3232 / 5000At timestep:     3333 / 5000At timestep:     3434 / 5000At timestep:     3535 / 5000At timestep:     3636 / 5000At timestep:     3737 / 5000At timestep:     3838 / 5000At timestep:     3939 / 5000At timestep:     4040 / 5000At timestep:     4141 / 5000At timestep:     4242 / 5000At timestep:     4343 / 5000At timestep:     4444 / 5000At timestep:     4545 / 5000At timestep:     4646 / 5000At timestep:     4747 / 5000At timestep:     4848 / 5000At timestep:     4949 / 5000At timestep:     5050 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     24 / 400At timestep:     47 / 400At timestep:     76 / 400At timestep:     94 / 400At timestep:     137 / 400At timestep:     166 / 400At timestep:     185 / 400At timestep:     274 / 400At timestep:     313 / 400At timestep:     332 / 400At timestep:     362 / 400At timestep:     386 / 400At timestep:     404 / 400Eval_AverageReturn : -30.263151168823242
Eval_StdReturn : 24.481287002563477
Eval_MaxReturn : -12.71245002746582
Eval_MinReturn : -108.70587158203125
Eval_AverageEpLen : 31.076923076923077
Train_AverageReturn : -163.6405487060547
Train_StdReturn : 34.4285888671875
Train_MaxReturn : -90.67053985595703
Train_MinReturn : -227.8916473388672
Train_AverageEpLen : 101.0
Train_EnvstepsSoFar : 5050
TimeSinceStart : 10.664371490478516
Training Loss : 0.3172035217285156
Initial_DataCollection_AverageReturn : -163.6405487060547
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...
At timestep:     27 / 1000At timestep:     48 / 1000At timestep:     63 / 1000At timestep:     93 / 1000At timestep:     111 / 1000At timestep:     138 / 1000At timestep:     155 / 1000At timestep:     256 / 1000At timestep:     285 / 1000At timestep:     301 / 1000At timestep:     322 / 1000At timestep:     423 / 1000At timestep:     438 / 1000At timestep:     497 / 1000At timestep:     517 / 1000At timestep:     537 / 1000At timestep:     552 / 1000At timestep:     574 / 1000At timestep:     629 / 1000At timestep:     681 / 1000At timestep:     713 / 1000At timestep:     814 / 1000At timestep:     915 / 1000At timestep:     1016 / 1000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     43 / 400At timestep:     60 / 400At timestep:     81 / 400At timestep:     101 / 400At timestep:     131 / 400At timestep:     149 / 400At timestep:     180 / 400At timestep:     206 / 400At timestep:     223 / 400At timestep:     241 / 400At timestep:     266 / 400At timestep:     298 / 400At timestep:     323 / 400At timestep:     399 / 400At timestep:     428 / 400Eval_AverageReturn : -26.98493766784668
Eval_StdReturn : 19.012510299682617
Eval_MaxReturn : -9.171807289123535
Eval_MinReturn : -85.61963653564453
Eval_AverageEpLen : 28.533333333333335
Train_AverageReturn : -56.69278335571289
Train_StdReturn : 64.79425811767578
Train_MaxReturn : -8.476840019226074
Train_MinReturn : -188.48545837402344
Train_AverageEpLen : 42.333333333333336
Train_EnvstepsSoFar : 6066
TimeSinceStart : 35.062169313430786
Training Loss : 0.3889557421207428
Initial_DataCollection_AverageReturn : -163.6405487060547
Done logging...




********** Iteration 2 ************

Collecting data to be used for training...
At timestep:     51 / 1000At timestep:     77 / 1000At timestep:     150 / 1000At timestep:     172 / 1000At timestep:     195 / 1000At timestep:     210 / 1000At timestep:     302 / 1000At timestep:     403 / 1000At timestep:     428 / 1000At timestep:     442 / 1000At timestep:     470 / 1000At timestep:     495 / 1000At timestep:     557 / 1000At timestep:     582 / 1000At timestep:     623 / 1000At timestep:     644 / 1000At timestep:     667 / 1000At timestep:     687 / 1000At timestep:     710 / 1000At timestep:     734 / 1000At timestep:     757 / 1000At timestep:     780 / 1000At timestep:     801 / 1000At timestep:     831 / 1000At timestep:     848 / 1000At timestep:     885 / 1000At timestep:     913 / 1000At timestep:     1014 / 1000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     18 / 400At timestep:     34 / 400At timestep:     77 / 400At timestep:     103 / 400At timestep:     154 / 400At timestep:     178 / 400At timestep:     201 / 400At timestep:     231 / 400At timestep:     332 / 400At timestep:     355 / 400At timestep:     456 / 400Eval_AverageReturn : -42.927852630615234
Eval_StdReturn : 39.1727180480957
Eval_MaxReturn : -10.570991516113281
Eval_MinReturn : -127.0127182006836
Eval_AverageEpLen : 41.45454545454545
Train_AverageReturn : -42.6104621887207
Train_StdReturn : 47.78700637817383
Train_MaxReturn : -8.20486068725586
Train_MinReturn : -186.69723510742188
Train_AverageEpLen : 36.214285714285715
Train_EnvstepsSoFar : 7080
TimeSinceStart : 60.199623584747314
Training Loss : 0.39618968963623047
Initial_DataCollection_AverageReturn : -163.6405487060547
Done logging...




********** Iteration 3 ************

Collecting data to be used for training...
At timestep:     72 / 1000At timestep:     105 / 1000At timestep:     130 / 1000At timestep:     190 / 1000At timestep:     210 / 1000At timestep:     232 / 1000At timestep:     278 / 1000At timestep:     306 / 1000At timestep:     324 / 1000At timestep:     340 / 1000At timestep:     383 / 1000At timestep:     407 / 1000At timestep:     434 / 1000At timestep:     459 / 1000At timestep:     478 / 1000At timestep:     499 / 1000At timestep:     521 / 1000At timestep:     541 / 1000At timestep:     636 / 1000At timestep:     657 / 1000At timestep:     675 / 1000At timestep:     691 / 1000At timestep:     713 / 1000At timestep:     732 / 1000At timestep:     756 / 1000At timestep:     822 / 1000At timestep:     895 / 1000At timestep:     909 / 1000At timestep:     967 / 1000At timestep:     985 / 1000At timestep:     1069 / 1000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     83 / 400At timestep:     119 / 400At timestep:     135 / 400At timestep:     150 / 400At timestep:     188 / 400At timestep:     212 / 400At timestep:     254 / 400At timestep:     333 / 400At timestep:     383 / 400At timestep:     410 / 400Eval_AverageReturn : -41.98633575439453
Eval_StdReturn : 29.84848976135254
Eval_MaxReturn : -9.57956314086914
Eval_MinReturn : -96.36624908447266
Eval_AverageEpLen : 41.0
Train_AverageReturn : -32.567928314208984
Train_StdReturn : 27.71111488342285
Train_MaxReturn : -9.191932678222656
Train_MinReturn : -99.71170043945312
Train_AverageEpLen : 34.483870967741936
Train_EnvstepsSoFar : 8149
TimeSinceStart : 86.56890225410461
Training Loss : 0.39688825607299805
Initial_DataCollection_AverageReturn : -163.6405487060547
Done logging...




********** Iteration 4 ************

Collecting data to be used for training...
At timestep:     43 / 1000At timestep:     69 / 1000At timestep:     98 / 1000At timestep:     133 / 1000At timestep:     232 / 1000At timestep:     264 / 1000At timestep:     309 / 1000At timestep:     326 / 1000At timestep:     349 / 1000At timestep:     374 / 1000At timestep:     405 / 1000At timestep:     462 / 1000At timestep:     477 / 1000At timestep:     521 / 1000At timestep:     549 / 1000At timestep:     570 / 1000At timestep:     597 / 1000At timestep:     640 / 1000At timestep:     674 / 1000At timestep:     723 / 1000At timestep:     738 / 1000At timestep:     761 / 1000At timestep:     796 / 1000At timestep:     816 / 1000At timestep:     844 / 1000At timestep:     862 / 1000At timestep:     887 / 1000At timestep:     910 / 1000At timestep:     925 / 1000At timestep:     939 / 1000At timestep:     965 / 1000At timestep:     981 / 1000At timestep:     1005 / 1000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     22 / 400At timestep:     61 / 400At timestep:     81 / 400At timestep:     110 / 400At timestep:     134 / 400At timestep:     163 / 400At timestep:     176 / 400At timestep:     193 / 400At timestep:     223 / 400At timestep:     250 / 400At timestep:     266 / 400At timestep:     332 / 400At timestep:     359 / 400At timestep:     388 / 400At timestep:     410 / 400Eval_AverageReturn : -25.390939712524414
Eval_StdReturn : 14.333970069885254
Eval_MaxReturn : -7.947649955749512
Eval_MinReturn : -69.27891540527344
Eval_AverageEpLen : 27.333333333333332
Train_AverageReturn : -29.357402801513672
Train_StdReturn : 26.18572425842285
Train_MaxReturn : -8.313626289367676
Train_MinReturn : -155.8484344482422
Train_AverageEpLen : 30.454545454545453
Train_EnvstepsSoFar : 9154
TimeSinceStart : 112.599374294281
Training Loss : 0.4039864242076874
Initial_DataCollection_AverageReturn : -163.6405487060547
Done logging...




********** Iteration 5 ************

Collecting data to be used for training...
At timestep:     24 / 1000At timestep:     44 / 1000At timestep:     80 / 1000At timestep:     103 / 1000At timestep:     139 / 1000At timestep:     156 / 1000At timestep:     190 / 1000At timestep:     219 / 1000At timestep:     242 / 1000At timestep:     305 / 1000At timestep:     323 / 1000At timestep:     346 / 1000At timestep:     362 / 1000At timestep:     387 / 1000At timestep:     453 / 1000At timestep:     475 / 1000At timestep:     505 / 1000At timestep:     537 / 1000At timestep:     564 / 1000At timestep:     596 / 1000At timestep:     615 / 1000At timestep:     642 / 1000At timestep:     668 / 1000At timestep:     684 / 1000At timestep:     785 / 1000At timestep:     828 / 1000At timestep:     862 / 1000At timestep:     878 / 1000At timestep:     907 / 1000At timestep:     958 / 1000At timestep:     983 / 1000At timestep:     999 / 1000At timestep:     1033 / 1000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     17 / 400At timestep:     51 / 400At timestep:     75 / 400At timestep:     94 / 400At timestep:     159 / 400At timestep:     181 / 400At timestep:     206 / 400At timestep:     289 / 400At timestep:     323 / 400At timestep:     348 / 400At timestep:     377 / 400At timestep:     395 / 400At timestep:     416 / 400Eval_AverageReturn : -32.876522064208984
Eval_StdReturn : 31.23786735534668
Eval_MaxReturn : -11.452277183532715
Eval_MinReturn : -131.42050170898438
Eval_AverageEpLen : 32.0
Train_AverageReturn : -32.87446212768555
Train_StdReturn : 32.47636413574219
Train_MaxReturn : -9.120068550109863
Train_MinReturn : -183.07861328125
Train_AverageEpLen : 31.303030303030305
Train_EnvstepsSoFar : 10187
TimeSinceStart : 139.51645231246948
Training Loss : 0.4069417715072632
Initial_DataCollection_AverageReturn : -163.6405487060547
Done logging...




********** Iteration 6 ************

Collecting data to be used for training...
At timestep:     30 / 1000At timestep:     55 / 1000At timestep:     76 / 1000At timestep:     111 / 1000At timestep:     133 / 1000At timestep:     153 / 1000At timestep:     179 / 1000At timestep:     194 / 1000At timestep:     213 / 1000At timestep:     235 / 1000At timestep:     276 / 1000At timestep:     303 / 1000At timestep:     320 / 1000At timestep:     343 / 1000At timestep:     364 / 1000At timestep:     391 / 1000At timestep:     413 / 1000At timestep:     436 / 1000At timestep:     462 / 1000At timestep:     484 / 1000At timestep:     509 / 1000At timestep:     544 / 1000At timestep:     566 / 1000At timestep:     586 / 1000At timestep:     625 / 1000At timestep:     649 / 1000At timestep:     702 / 1000At timestep:     784 / 1000At timestep:     807 / 1000At timestep:     824 / 1000At timestep:     868 / 1000At timestep:     884 / 1000At timestep:     908 / 1000At timestep:     924 / 1000At timestep:     950 / 1000At timestep:     999 / 1000At timestep:     1026 / 1000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     35 / 400At timestep:     58 / 400At timestep:     89 / 400At timestep:     104 / 400At timestep:     129 / 400At timestep:     150 / 400At timestep:     173 / 400At timestep:     196 / 400At timestep:     238 / 400At timestep:     261 / 400At timestep:     278 / 400At timestep:     300 / 400At timestep:     326 / 400At timestep:     347 / 400At timestep:     401 / 400Eval_AverageReturn : -24.974376678466797
Eval_StdReturn : 14.648033142089844
Eval_MaxReturn : -8.357959747314453
Eval_MinReturn : -60.211185455322266
Eval_AverageEpLen : 26.733333333333334
Train_AverageReturn : -27.078834533691406
Train_StdReturn : 21.350107192993164
Train_MaxReturn : -8.619129180908203
Train_MinReturn : -127.470703125
Train_AverageEpLen : 27.72972972972973
Train_EnvstepsSoFar : 11213
TimeSinceStart : 166.16588044166565
Training Loss : 0.4015129506587982
Initial_DataCollection_AverageReturn : -163.6405487060547
Done logging...




********** Iteration 7 ************

Collecting data to be used for training...
At timestep:     27 / 1000At timestep:     46 / 1000At timestep:     80 / 1000At timestep:     127 / 1000At timestep:     144 / 1000At timestep:     163 / 1000At timestep:     189 / 1000At timestep:     205 / 1000At timestep:     227 / 1000At timestep:     314 / 1000At timestep:     335 / 1000At timestep:     425 / 1000At timestep:     490 / 1000At timestep:     542 / 1000At timestep:     557 / 1000At timestep:     597 / 1000At timestep:     630 / 1000At timestep:     656 / 1000At timestep:     682 / 1000At timestep:     762 / 1000At timestep:     813 / 1000At timestep:     840 / 1000At timestep:     867 / 1000At timestep:     925 / 1000At timestep:     969 / 1000At timestep:     986 / 1000At timestep:     1010 / 1000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     30 / 400At timestep:     46 / 400At timestep:     78 / 400At timestep:     107 / 400At timestep:     158 / 400At timestep:     173 / 400At timestep:     201 / 400At timestep:     227 / 400At timestep:     253 / 400At timestep:     277 / 400At timestep:     344 / 400At timestep:     362 / 400At timestep:     403 / 400Eval_AverageReturn : -28.73512077331543
Eval_StdReturn : 18.74089241027832
Eval_MaxReturn : -8.496576309204102
Eval_MinReturn : -78.26710510253906
Eval_AverageEpLen : 31.0
Train_AverageReturn : -39.596160888671875
Train_StdReturn : 32.045989990234375
Train_MaxReturn : -8.489358901977539
Train_MinReturn : -147.63780212402344
Train_AverageEpLen : 37.407407407407405
Train_EnvstepsSoFar : 12223
TimeSinceStart : 192.81374216079712
Training Loss : 0.4178837239742279
Initial_DataCollection_AverageReturn : -163.6405487060547
Done logging...




********** Iteration 8 ************

Collecting data to be used for training...
At timestep:     44 / 1000At timestep:    /home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/spaces/box.py:128: UserWarning: [33mWARN: Box bound precision lowered by casting to float32[0m
  logger.warn(f"Box bound precision lowered by casting to {self.dtype}")
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:191: UserWarning: [33mWARN: Future gym versions will require that `Env.reset` can be passed `return_info` to return information from the environment resetting.[0m
  "Future gym versions will require that `Env.reset` can be passed `return_info` to return information from the environment resetting."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:196: UserWarning: [33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.[0m
  "Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:142: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64[0m
  f"{pre} was expecting numpy array dtype to be {observation_space.dtype}, actual type: {obs.dtype}"
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: [33mWARN: The obs returned by the `reset()` method is not within the observation space.[0m
  logger.warn(f"{pre} is not within the observation space.")
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  "Core environment is written in old step API which returns one bool instead of two. "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:235: UserWarning: [33mWARN: Expects `done` signal to be a boolean, actual type: <class 'numpy.float64'>[0m
  f"Expects `done` signal to be a boolean, actual type: {type(done)}"
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:142: UserWarning: [33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: float64[0m
  f"{pre} was expecting numpy array dtype to be {observation_space.dtype}, actual type: {obs.dtype}"
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: [33mWARN: The obs returned by the `step()` method is not within the observation space.[0m
  logger.warn(f"{pre} is not within the observation space.")
 95 / 1000At timestep:     128 / 1000At timestep:     156 / 1000At timestep:     175 / 1000At timestep:     216 / 1000At timestep:     237 / 1000At timestep:     255 / 1000At timestep:     281 / 1000At timestep:     300 / 1000At timestep:     319 / 1000At timestep:     340 / 1000At timestep:     381 / 1000At timestep:     403 / 1000At timestep:     436 / 1000At timestep:     470 / 1000At timestep:     505 / 1000At timestep:     531 / 1000At timestep:     580 / 1000At timestep:     595 / 1000At timestep:     613 / 1000At timestep:     635 / 1000At timestep:     666 / 1000At timestep:     686 / 1000At timestep:     740 / 1000At timestep:     762 / 1000At timestep:     795 / 1000At timestep:     817 / 1000At timestep:     879 / 1000At timestep:     898 / 1000At timestep:     940 / 1000At timestep:     958 / 1000At timestep:     979 / 1000At timestep:     1001 / 1000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     16 / 400At timestep:     44 / 400At timestep:     72 / 400At timestep:     89 / 400At timestep:     113 / 400At timestep:     148 / 400At timestep:     175 / 400At timestep:     193 / 400At timestep:     213 / 400At timestep:     240 / 400At timestep:     266 / 400At timestep:     292 / 400At timestep:     344 / 400At timestep:     364 / 400At timestep:     390 / 400At timestep:     410 / 400Eval_AverageReturn : -22.16809844970703
Eval_StdReturn : 14.804327964782715
Eval_MaxReturn : -9.784408569335938
Eval_MinReturn : -75.53021240234375
Eval_AverageEpLen : 25.625
Train_AverageReturn : -28.869924545288086
Train_StdReturn : 18.033903121948242
Train_MaxReturn : -9.085773468017578
Train_MinReturn : -73.11389923095703
Train_AverageEpLen : 29.441176470588236
Train_EnvstepsSoFar : 13224
TimeSinceStart : 219.92450165748596
Training Loss : 0.41433966159820557
Initial_DataCollection_AverageReturn : -163.6405487060547
Done logging...




********** Iteration 9 ************

Collecting data to be used for training...
At timestep:     19 / 1000At timestep:     46 / 1000At timestep:     76 / 1000At timestep:     108 / 1000At timestep:     133 / 1000At timestep:     151 / 1000At timestep:     167 / 1000At timestep:     183 / 1000At timestep:     203 / 1000At timestep:     227 / 1000At timestep:     252 / 1000At timestep:     271 / 1000At timestep:     288 / 1000At timestep:     309 / 1000At timestep:     335 / 1000At timestep:     350 / 1000At timestep:     381 / 1000At timestep:     403 / 1000At timestep:     427 / 1000At timestep:     445 / 1000At timestep:     467 / 1000At timestep:     499 / 1000At timestep:     518 / 1000At timestep:     547 / 1000At timestep:     573 / 1000At timestep:     598 / 1000At timestep:     615 / 1000At timestep:     668 / 1000At timestep:     708 / 1000At timestep:     741 / 1000At timestep:     783 / 1000At timestep:     882 / 1000At timestep:     924 / 1000At timestep:     945 / 1000At timestep:     970 / 1000At timestep:     994 / 1000At timestep:     1017 / 1000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     31 / 400At timestep:     58 / 400At timestep:     86 / 400At timestep:     116 / 400At timestep:     134 / 400At timestep:     158 / 400At timestep:     181 / 400At timestep:     219 / 400At timestep:     320 / 400At timestep:     351 / 400At timestep:     373 / 400At timestep:     389 / 400At timestep:     425 / 400Eval_AverageReturn : -36.426109313964844
Eval_StdReturn : 39.40607452392578
Eval_MaxReturn : -10.757561683654785
Eval_MinReturn : -168.7849884033203
Eval_AverageEpLen : 32.69230769230769
Train_AverageReturn : -27.2613582611084
Train_StdReturn : 25.32721519470215
Train_MaxReturn : -8.65611743927002
Train_MinReturn : -160.64520263671875
Train_AverageEpLen : 27.486486486486488
Train_EnvstepsSoFar : 14241
TimeSinceStart : 247.75270128250122
Training Loss : 0.4001959264278412
Initial_DataCollection_AverageReturn : -163.6405487060547
Done logging...




********** Iteration 10 ************

Collecting data to be used for training...
At timestep:     17 / 1000At timestep:     32 / 1000At timestep:     63 / 1000At timestep:     84 / 1000At timestep:     102 / 1000At timestep:     128 / 1000At timestep:     198 / 1000At timestep:     218 / 1000At timestep:     252 / 1000At timestep:     281 / 1000At timestep:     302 / 1000At timestep:     332 / 1000At timestep:     352 / 1000At timestep:     376 / 1000At timestep:     445 / 1000At timestep:     467 / 1000At timestep:     492 / 1000At timestep:     516 / 1000At timestep:     545 / 1000At timestep:     572 / 1000At timestep:     593 / 1000At timestep:     611 / 1000At timestep:     631 / 1000At timestep:     664 / 1000At timestep:     691 / 1000At timestep:     711 / 1000At timestep:     754 / 1000At timestep:     783 / 1000At timestep:     840 / 1000At timestep:     857 / 1000At timestep:     885 / 1000At timestep:     931 / 1000At timestep:     955 / 1000At timestep:     1010 / 1000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     22 / 400At timestep:     47 / 400At timestep:     76 / 400At timestep:     103 / 400At timestep:     146 / 400At timestep:     166 / 400At timestep:     192 / 400At timestep:     224 / 400At timestep:     255 / 400At timestep:     278 / 400At timestep:     307 / 400At timestep:     350 / 400At timestep:     366 / 400At timestep:     395 / 400At timestep:     412 / 400Eval_AverageReturn : -26.7607364654541
Eval_StdReturn : 12.489225387573242
Eval_MaxReturn : -12.256064414978027
Eval_MinReturn : -58.77938461303711
Eval_AverageEpLen : 27.466666666666665
Train_AverageReturn : -30.347021102905273
Train_StdReturn : 20.668176651000977
Train_MaxReturn : -9.470983505249023
Train_MinReturn : -102.50846099853516
Train_AverageEpLen : 29.705882352941178
Train_EnvstepsSoFar : 15251
TimeSinceStart : 275.6368045806885
Training Loss : 0.4043246805667877
Initial_DataCollection_AverageReturn : -163.6405487060547
Done logging...




********** Iteration 11 ************

Collecting data to be used for training...
At timestep:     48 / 1000At timestep:     67 / 1000At timestep:     85 / 1000At timestep:     141 / 1000At timestep:     159 / 1000At timestep:     188 / 1000At timestep:     218 / 1000At timestep:     246 / 1000At timestep:     273 / 1000At timestep:     295 / 1000At timestep:     321 / 1000At timestep:     349 / 1000At timestep:     376 / 1000At timestep:     398 / 1000At timestep:     446 / 1000At timestep:     482 / 1000At timestep:     501 / 1000At timestep:     527 / 1000At timestep:     543 / 1000At timestep:     557 / 1000At timestep:     604 / 1000At timestep:     622 / 1000At timestep:     651 / 1000At timestep:     686 / 1000At timestep:     704 / 1000At timestep:     734 / 1000At timestep:     757 / 1000At timestep:     774 / 1000At timestep:     810 / 1000At timestep:     825 / 1000At timestep:     848 / 1000At timestep:     939 / 1000At timestep:     958 / 1000At timestep:     1052 / 1000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     21 / 400At timestep:     45 / 400At timestep:     68 / 400At timestep:     87 / 400At timestep:     107 / 400At timestep:     151 / 400At timestep:     240 / 400At timestep:     276 / 400At timestep:     297 / 400At timestep:     322 / 400At timestep:     339 / 400At timestep:     362 / 400At timestep:     386 / 400At timestep:     411 / 400Eval_AverageReturn : -30.00228500366211
Eval_StdReturn : 31.989564895629883
Eval_MaxReturn : -12.322982788085938
Eval_MinReturn : -138.97537231445312
Eval_AverageEpLen : 29.357142857142858
Train_AverageReturn : -31.14488983154297
Train_StdReturn : 28.118694305419922
Train_MaxReturn : -7.88134241104126
Train_MinReturn : -145.6745147705078
Train_AverageEpLen : 30.941176470588236
Train_EnvstepsSoFar : 16303
TimeSinceStart : 304.6602511405945
Training Loss : 0.3992149829864502
Initial_DataCollection_AverageReturn : -163.6405487060547
Done logging...





LOGGING TO:  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q4_reacher_horizon5_reacher-cs285-v0_02-11-2022_20-39-11 



########################
logging outputs to  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q4_reacher_horizon5_reacher-cs285-v0_02-11-2022_20-39-11
########################
Using GPU id 0
Using action sampling strategy: random


********** Iteration 0 ************

Collecting data to be used for training...
At timestep:     201 / 20000At timestep:     402 / 20000At timestep:     603 / 20000At timestep:     804 / 20000At timestep:     1005 / 20000At timestep:     1206 / 20000At timestep:     1407 / 20000At timestep:     1608 / 20000At timestep:     1809 / 20000At timestep:     2010 / 20000At timestep:     2211 / 20000At timestep:     2412 / 20000At timestep:     2613 / 20000At timestep:     2814 / 20000At timestep:     3015 / 20000At timestep:     3216 / 20000At timestep:     3417 / 20000At timestep:     3618 / 20000At timestep:     3819 / 20000At timestep:     4020 / 20000At timestep:     4221 / 20000At timestep:     4422 / 20000At timestep:     4623 / 20000At timestep:     4824 / 20000At timestep:     5025 / 20000At timestep:     5226 / 20000At timestep:     5427 / 20000At timestep:     5628 / 20000At timestep:     5829 / 20000At timestep:     6030 / 20000At timestep:     6231 / 20000At timestep:     6432 / 20000At timestep:     6633 / 20000At timestep:     6834 / 20000At timestep:     7035 / 20000At timestep:     7236 / 20000At timestep:     7437 / 20000At timestep:     7638 / 20000At timestep:     7839 / 20000At timestep:     8040 / 20000At timestep:     8241 / 20000At timestep:     8442 / 20000At timestep:     8643 / 20000At timestep:     8844 / 20000At timestep:     9045 / 20000At timestep:     9246 / 20000At timestep:     9447 / 20000At timestep:     9648 / 20000At timestep:     9849 / 20000At timestep:     10050 / 20000At timestep:     10251 / 20000At timestep:     10452 / 20000At timestep:     10653 / 20000At timestep:     10854 / 20000At timestep:     11055 / 20000At timestep:     11256 / 20000At timestep:     11457 / 20000At timestep:     11658 / 20000At timestep:     11859 / 20000At timestep:     12060 / 20000At timestep:     12261 / 20000At timestep:     12462 / 20000At timestep:     12663 / 20000At timestep:     12864 / 20000At timestep:     13065 / 20000At timestep:     13266 / 20000At timestep:     13467 / 20000At timestep:     13668 / 20000At timestep:     13869 / 20000At timestep:     14070 / 20000At timestep:     14271 / 20000At timestep:     14472 / 20000At timestep:     14673 / 20000At timestep:     14874 / 20000At timestep:     15075 / 20000At timestep:     15276 / 20000At timestep:     15477 / 20000At timestep:     15678 / 20000At timestep:     15879 / 20000At timestep:     16080 / 20000At timestep:     16281 / 20000At timestep:     16482 / 20000At timestep:     16683 / 20000At timestep:     16884 / 20000At timestep:     17085 / 20000At timestep:     17286 / 20000At timestep:     17487 / 20000At timestep:     17688 / 20000At timestep:     17889 / 20000At timestep:     18090 / 20000At timestep:     18291 / 20000At timestep:     18492 / 20000At timestep:     18693 / 20000At timestep:     18894 / 20000At timestep:     19095 / 20000At timestep:     19296 / 20000At timestep:     19497 / 20000At timestep:     19698 / 20000At timestep:     19899 / 20000At timestep:     20100 / 20000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -1005.14501953125
Eval_StdReturn : 253.35964965820312
Eval_MaxReturn : -751.7853393554688
Eval_MinReturn : -1258.504638671875
Eval_AverageEpLen : 201.0
Train_AverageReturn : -1887.0548095703125
Train_StdReturn : 400.1144714355469
Train_MaxReturn : -957.108154296875
Train_MinReturn : -2589.48681640625
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 20100
TimeSinceStart : 12.112621068954468
Training Loss : 0.19861221313476562
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -330.573974609375
Eval_StdReturn : 13.624008178710938
Eval_MaxReturn : -316.949951171875
Eval_MinReturn : -344.1979675292969
Eval_AverageEpLen : 201.0
Train_AverageReturn : -798.7741088867188
Train_StdReturn : 270.2233581542969
Train_MaxReturn : -628.5902709960938
Train_MinReturn : -1266.0267333984375
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 20904
TimeSinceStart : 28.28430986404419
Training Loss : 0.19373579323291779
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 2 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -260.1781311035156
Eval_StdReturn : 6.406501770019531
Eval_MaxReturn : -253.77162170410156
Eval_MinReturn : -266.5846252441406
Eval_AverageEpLen : 201.0
Train_AverageReturn : -327.2584533691406
Train_StdReturn : 9.996636390686035
Train_MaxReturn : -309.99090576171875
Train_MinReturn : -334.1643371582031
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 21708
TimeSinceStart : 44.662737131118774
Training Loss : 0.16905196011066437
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 3 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -280.150390625
Eval_StdReturn : 2.0534515380859375
Eval_MaxReturn : -278.096923828125
Eval_MinReturn : -282.2038269042969
Eval_AverageEpLen : 201.0
Train_AverageReturn : -386.2860107421875
Train_StdReturn : 170.4110107421875
Train_MaxReturn : -252.17758178710938
Train_MinReturn : -678.8855590820312
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 22512
TimeSinceStart : 61.823949098587036
Training Loss : 0.17148101329803467
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 4 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -301.87994384765625
Eval_StdReturn : 11.352325439453125
Eval_MaxReturn : -290.5276184082031
Eval_MinReturn : -313.2322692871094
Eval_AverageEpLen : 201.0
Train_AverageReturn : -338.5361633300781
Train_StdReturn : 83.3994140625
Train_MaxReturn : -239.3332061767578
Train_MinReturn : -436.7630615234375
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 23316
TimeSinceStart : 79.95997548103333
Training Loss : 0.1640269160270691
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 5 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -284.3030090332031
Eval_StdReturn : 18.6494140625
Eval_MaxReturn : -265.6535949707031
Eval_MinReturn : -302.9524230957031
Eval_AverageEpLen : 201.0
Train_AverageReturn : -297.2886047363281
Train_StdReturn : 33.01776885986328
Train_MaxReturn : -264.0899658203125/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/core.py:257: DeprecationWarning: [33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.[0m
  "Function `env.seed(seed)` is marked as deprecated and will be removed in the future. "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  "Core environment is written in old step API which returns one bool instead of two. "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:235: UserWarning: [33mWARN: Expects `done` signal to be a boolean, actual type: <class 'numpy.float64'>[0m
  f"Expects `done` signal to be a boolean, actual type: {type(done)}"

Train_MinReturn : -343.0331726074219
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 24120
TimeSinceStart : 98.12989640235901
Training Loss : 0.16890008747577667
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 6 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -348.7003173828125
Eval_StdReturn : 34.65074157714844
Eval_MaxReturn : -314.049560546875
Eval_MinReturn : -383.3510437011719
Eval_AverageEpLen : 201.0
Train_AverageReturn : -284.8424072265625
Train_StdReturn : 17.097217559814453
Train_MaxReturn : -262.4042053222656
Train_MinReturn : -309.50482177734375
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 24924
TimeSinceStart : 116.39931082725525
Training Loss : 0.15771906077861786
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 7 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -285.130615234375
Eval_StdReturn : 3.1643524169921875
Eval_MaxReturn : -281.9662780761719
Eval_MinReturn : -288.29498291015625
Eval_AverageEpLen : 201.0
Train_AverageReturn : -314.0294494628906
Train_StdReturn : 30.725717544555664
Train_MaxReturn : -280.1845397949219
Train_MinReturn : -354.8011474609375
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 25728
TimeSinceStart : 135.29193830490112
Training Loss : 0.15821607410907745
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 8 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -273.91046142578125
Eval_StdReturn : 1.6671142578125
Eval_MaxReturn : -272.24334716796875
Eval_MinReturn : -275.57757568359375
Eval_AverageEpLen : 201.0
Train_AverageReturn : -268.688232421875
Train_StdReturn : 11.977439880371094
Train_MaxReturn : -249.2322998046875
Train_MinReturn : -281.9388427734375
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 26532
TimeSinceStart : 154.19852995872498
Training Loss : 0.1541047990322113
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 9 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -280.64019775390625
Eval_StdReturn : 17.091888427734375
Eval_MaxReturn : -263.5483093261719
Eval_MinReturn : -297.7320861816406
Eval_AverageEpLen : 201.0
Train_AverageReturn : -289.552978515625
Train_StdReturn : 33.392547607421875
Train_MaxReturn : -267.5433654785156
Train_MinReturn : -347.31451416015625
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 27336
TimeSinceStart : 173.24848103523254
Training Loss : 0.15277040004730225
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 10 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -284.8114929199219
Eval_StdReturn : 17.0660400390625
Eval_MaxReturn : -267.7454528808594
Eval_MinReturn : -301.8775329589844
Eval_AverageEpLen : 201.0
Train_AverageReturn : -291.58831787109375
Train_StdReturn : 14.539133071899414
Train_MaxReturn : -276.1702880859375
Train_MinReturn : -306.7977600097656
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 28140
TimeSinceStart : 192.47436332702637
Training Loss : 0.15595251321792603
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 11 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -262.14202880859375
Eval_StdReturn : 18.901138305664062
Eval_MaxReturn : -243.24090576171875
Eval_MinReturn : -281.0431823730469
Eval_AverageEpLen : 201.0
Train_AverageReturn : -296.6015319824219
Train_StdReturn : 33.272926330566406
Train_MaxReturn : -256.1578063964844
Train_MinReturn : -333.7460021972656
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 28944
TimeSinceStart : 211.83969736099243
Training Loss : 0.15449468791484833
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 12 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -269.29302978515625
Eval_StdReturn : 23.561737060546875
Eval_MaxReturn : -245.73129272460938
Eval_MinReturn : -292.8547668457031
Eval_AverageEpLen : 201.0
Train_AverageReturn : -268.78094482421875
Train_StdReturn : 4.058375835418701
Train_MaxReturn : -263.0252990722656
Train_MinReturn : -274.42645263671875
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 29748
TimeSinceStart : 231.28556895256042
Training Loss : 0.14992856979370117
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 13 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -260.7304992675781
Eval_StdReturn : 3.92974853515625
Eval_MaxReturn : -256.8007507324219
Eval_MinReturn : -264.6602478027344
Eval_AverageEpLen : 201.0
Train_AverageReturn : -281.5851135253906
Train_StdReturn : 29.522478103637695
Train_MaxReturn : -250.6980438232422
Train_MinReturn : -327.6465148925781
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 30552
TimeSinceStart : 250.81257700920105
Training Loss : 0.14606522023677826
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 14 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -285.4742431640625
Eval_StdReturn : 6.0436248779296875
Eval_MaxReturn : -279.4306335449219
Eval_MinReturn : -291.51788330078125
Eval_AverageEpLen : 201.0
Train_AverageReturn : -269.22723388671875
Train_StdReturn : 13.068937301635742
Train_MaxReturn : -254.85166931152344
Train_MinReturn : -287.0801696777344
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 31356
TimeSinceStart : 270.24124932289124
Training Loss : 0.14319871366024017
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...





LOGGING TO:  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q4_reacher_horizon15_reacher-cs285-v0_02-11-2022_20-43-44 



########################
logging outputs to  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q4_reacher_horizon15_reacher-cs285-v0_02-11-2022_20-43-44
########################
Using GPU id 0
Using action sampling strategy: random


********** Iteration 0 ************

Collecting data to be used for training...
At timestep:     201 / 20000At timestep:     402 / 20000At timestep:     603 / 20000At timestep:     804 / 20000At timestep:     1005 / 20000At timestep:     1206 / 20000At timestep:     1407 / 20000At timestep:     1608 / 20000At timestep:     1809 / 20000At timestep:     2010 / 20000At timestep:     2211 / 20000At timestep:     2412 / 20000At timestep:     2613 / 20000At timestep:     2814 / 20000At timestep:     3015 / 20000At timestep:     3216 / 20000At timestep:     3417 / 20000At timestep:     3618 / 20000At timestep:     3819 / 20000At timestep:     4020 / 20000At timestep:     4221 / 20000At timestep:     4422 / 20000At timestep:     4623 / 20000At timestep:     4824 / 20000At timestep:     5025 / 20000At timestep:     5226 / 20000At timestep:     5427 / 20000At timestep:     5628 / 20000At timestep:     5829 / 20000At timestep:     6030 / 20000At timestep:     6231 / 20000At timestep:     6432 / 20000At timestep:     6633 / 20000At timestep:     6834 / 20000At timestep:     7035 / 20000At timestep:     7236 / 20000At timestep:     7437 / 20000At timestep:     7638 / 20000At timestep:     7839 / 20000At timestep:     8040 / 20000At timestep:     8241 / 20000At timestep:     8442 / 20000At timestep:     8643 / 20000At timestep:     8844 / 20000At timestep:     9045 / 20000At timestep:     9246 / 20000At timestep:     9447 / 20000At timestep:     9648 / 20000At timestep:     9849 / 20000At timestep:     10050 / 20000At timestep:     10251 / 20000At timestep:     10452 / 20000At timestep:     10653 / 20000At timestep:     10854 / 20000At timestep:     11055 / 20000At timestep:     11256 / 20000At timestep:     11457 / 20000At timestep:     11658 / 20000At timestep:     11859 / 20000At timestep:     12060 / 20000At timestep:     12261 / 20000At timestep:     12462 / 20000At timestep:     12663 / 20000At timestep:     12864 / 20000At timestep:     13065 / 20000At timestep:     13266 / 20000At timestep:     13467 / 20000At timestep:     13668 / 20000At timestep:     13869 / 20000At timestep:     14070 / 20000At timestep:     14271 / 20000At timestep:     14472 / 20000At timestep:     14673 / 20000At timestep:     14874 / 20000At timestep:     15075 / 20000At timestep:     15276 / 20000At timestep:     15477 / 20000At timestep:     15678 / 20000At timestep:     15879 / 20000At timestep:     16080 / 20000At timestep:     16281 / 20000At timestep:     16482 / 20000At timestep:     16683 / 20000At timestep:     16884 / 20000At timestep:     17085 / 20000At timestep:     17286 / 20000At timestep:     17487 / 20000At timestep:     17688 / 20000At timestep:     17889 / 20000At timestep:     18090 / 20000At timestep:     18291 / 20000At timestep:     18492 / 20000At timestep:     18693 / 20000At timestep:     18894 / 20000At timestep:     19095 / 20000At timestep:     19296 / 20000At timestep:     19497 / 20000At timestep:     19698 / 20000At timestep:     19899 / 20000At timestep:     20100 / 20000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -396.3345642089844
Eval_StdReturn : 38.972869873046875
Eval_MaxReturn : -357.3616943359375
Eval_MinReturn : -435.30743408203125
Eval_AverageEpLen : 201.0
Train_AverageReturn : -1887.0548095703125
Train_StdReturn : 400.1144714355469
Train_MaxReturn : -957.108154296875
Train_MinReturn : -2589.48681640625
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 20100
TimeSinceStart : 23.005382537841797
Training Loss : 0.19861221313476562
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -327.1573486328125
Eval_StdReturn : 18.106338500976562
Eval_MaxReturn : -309.051025390625
Eval_MinReturn : -345.2637023925781
Eval_AverageEpLen : 201.0
Train_AverageReturn : -397.25927734375
Train_StdReturn : 39.00728225708008
Train_MaxReturn : -343.05999755859375
Train_MinReturn : -453.3472900390625
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 20904
TimeSinceStart : 68.39162373542786
Training Loss : 0.18764610588550568
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 2 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -292.4256896972656
Eval_StdReturn : 2.489471435546875
Eval_MaxReturn : -289.93621826171875
Eval_MinReturn : -294.9151611328125
Eval_AverageEpLen : 201.0
Train_AverageReturn : -310.52691650390625
Train_StdReturn : 25.591379165649414
Train_MaxReturn : -270.78485107421875
Train_MinReturn : -340.0413513183594
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 21708
TimeSinceStart : 114.17813754081726
Training Loss : 0.17508584260940552
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 3 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -284.72943115234375
Eval_StdReturn : 5.9605255126953125
Eval_MaxReturn : -278.7689208984375
Eval_MinReturn : -290.6899719238281
Eval_AverageEpLen : 201.0
Train_AverageReturn : -287.231689453125
Train_StdReturn : 24.54082679748535
Train_MaxReturn : -261.9548645019531
Train_MinReturn : -320.72833251953125
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 22512
TimeSinceStart : 160.78779768943787
Training Loss : 0.17423711717128754
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 4 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -262.4554443359375
Eval_StdReturn : 19.835693359375
Eval_MaxReturn : -242.6197509765625
Eval_MinReturn : -282.2911376953125
Eval_AverageEpLen : 201.0
Train_AverageReturn : -293.239501953125
Train_StdReturn : 28.458168029785156
Train_MaxReturn : -262.61572265625
Train_MinReturn : -339.1766662597656
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 23316
TimeSinceStart : 207.693603515625
Training Loss : 0.17135943472385406
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 5 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -287.5777587890625
Eval_StdReturn : 6.1334228515625
Eval_MaxReturn : -281.4443359375
Eval_MinReturn : -293.711181640625
Eval_AverageEpLen : 201.0
Train_AverageReturn : -293.7406311035156
Train_StdReturn : 27.99425506591797
Train_MaxReturn : -265.9267578125/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/core.py:257: DeprecationWarning: [33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.[0m
  "Function `env.seed(seed)` is marked as deprecated and will be removed in the future. "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  "Core environment is written in old step API which returns one bool instead of two. "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:235: UserWarning: [33mWARN: Expects `done` signal to be a boolean, actual type: <class 'numpy.float64'>[0m
  f"Expects `done` signal to be a boolean, actual type: {type(done)}"

Train_MinReturn : -327.1601257324219
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 24120
TimeSinceStart : 254.39627385139465
Training Loss : 0.16792690753936768
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 6 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -282.8926086425781
Eval_StdReturn : 12.81390380859375
Eval_MaxReturn : -270.0787048339844
Eval_MinReturn : -295.7065124511719
Eval_AverageEpLen : 201.0
Train_AverageReturn : -281.184326171875
Train_StdReturn : 10.676912307739258
Train_MaxReturn : -270.8216552734375
Train_MinReturn : -296.4095764160156
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 24924
TimeSinceStart : 301.37962198257446
Training Loss : 0.1649288535118103
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 7 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -311.91802978515625
Eval_StdReturn : 7.61865234375
Eval_MaxReturn : -304.29937744140625
Eval_MinReturn : -319.53668212890625
Eval_AverageEpLen : 201.0
Train_AverageReturn : -281.0299377441406
Train_StdReturn : 8.942580223083496
Train_MaxReturn : -270.7113342285156
Train_MinReturn : -293.2948913574219
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 25728
TimeSinceStart : 348.45049357414246
Training Loss : 0.1614086925983429
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 8 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -287.73663330078125
Eval_StdReturn : 1.6553497314453125
Eval_MaxReturn : -286.081298828125
Eval_MinReturn : -289.3919982910156
Eval_AverageEpLen : 201.0
Train_AverageReturn : -309.3323669433594
Train_StdReturn : 28.522993087768555
Train_MaxReturn : -268.4223327636719
Train_MinReturn : -348.8840026855469
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 26532
TimeSinceStart : 395.6747577190399
Training Loss : 0.15756551921367645
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 9 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -268.67242431640625
Eval_StdReturn : 6.4189910888671875
Eval_MaxReturn : -262.2534484863281
Eval_MinReturn : -275.0914306640625
Eval_AverageEpLen : 201.0
Train_AverageReturn : -280.7667236328125
Train_StdReturn : 2.2171177864074707
Train_MaxReturn : -277.5227966308594
Train_MinReturn : -283.7686462402344
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 27336
TimeSinceStart : 443.0586895942688
Training Loss : 0.15907151997089386
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 10 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -322.2032470703125
Eval_StdReturn : 12.989273071289062
Eval_MaxReturn : -309.2139587402344
Eval_MinReturn : -335.1925048828125
Eval_AverageEpLen : 201.0
Train_AverageReturn : -300.343994140625
Train_StdReturn : 32.680908203125
Train_MaxReturn : -272.26165771484375
Train_MinReturn : -355.7387390136719
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 28140
TimeSinceStart : 490.53455686569214
Training Loss : 0.15694831311702728
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 11 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -275.8329162597656
Eval_StdReturn : 5.938629150390625
Eval_MaxReturn : -269.894287109375
Eval_MinReturn : -281.77154541015625
Eval_AverageEpLen : 201.0
Train_AverageReturn : -302.4486083984375
Train_StdReturn : 25.713428497314453
Train_MaxReturn : -274.5071105957031
Train_MinReturn : -341.14703369140625
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 28944
TimeSinceStart : 538.1445534229279
Training Loss : 0.15532799065113068
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 12 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -285.51171875
Eval_StdReturn : 5.690277099609375
Eval_MaxReturn : -279.8214416503906
Eval_MinReturn : -291.2019958496094
Eval_AverageEpLen : 201.0
Train_AverageReturn : -336.35797119140625
Train_StdReturn : 16.93624496459961
Train_MaxReturn : -314.5849914550781
Train_MinReturn : -360.8551025390625
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 29748
TimeSinceStart : 586.0244331359863
Training Loss : 0.15115882456302643
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 13 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -335.2985534667969
Eval_StdReturn : 24.407318115234375
Eval_MaxReturn : -310.8912353515625
Eval_MinReturn : -359.70587158203125
Eval_AverageEpLen : 201.0
Train_AverageReturn : -300.5268249511719
Train_StdReturn : 20.60507583618164
Train_MaxReturn : -269.3211364746094
Train_MinReturn : -324.82147216796875
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 30552
TimeSinceStart : 634.0675361156464
Training Loss : 0.14951716363430023
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 14 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -300.33905029296875
Eval_StdReturn : 9.290298461914062
Eval_MaxReturn : -291.04876708984375
Eval_MinReturn : -309.6293640136719
Eval_AverageEpLen : 201.0
Train_AverageReturn : -293.3226623535156
Train_StdReturn : 9.284889221191406
Train_MaxReturn : -277.289794921875
Train_MinReturn : -299.8496398925781
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 31356
TimeSinceStart : 681.8785710334778
Training Loss : 0.1519385576248169
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...





LOGGING TO:  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q4_reacher_horizon30_reacher-cs285-v0_02-11-2022_20-55-10 



########################
logging outputs to  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q4_reacher_horizon30_reacher-cs285-v0_02-11-2022_20-55-10
########################
Using GPU id 0
Using action sampling strategy: random


********** Iteration 0 ************

Collecting data to be used for training...
At timestep:     201 / 20000At timestep:     402 / 20000At timestep:     603 / 20000At timestep:     804 / 20000At timestep:     1005 / 20000At timestep:     1206 / 20000At timestep:     1407 / 20000At timestep:     1608 / 20000At timestep:     1809 / 20000At timestep:     2010 / 20000At timestep:     2211 / 20000At timestep:     2412 / 20000At timestep:     2613 / 20000At timestep:     2814 / 20000At timestep:     3015 / 20000At timestep:     3216 / 20000At timestep:     3417 / 20000At timestep:     3618 / 20000At timestep:     3819 / 20000At timestep:     4020 / 20000At timestep:     4221 / 20000At timestep:     4422 / 20000At timestep:     4623 / 20000At timestep:     4824 / 20000At timestep:     5025 / 20000At timestep:     5226 / 20000At timestep:     5427 / 20000At timestep:     5628 / 20000At timestep:     5829 / 20000At timestep:     6030 / 20000At timestep:     6231 / 20000At timestep:     6432 / 20000At timestep:     6633 / 20000At timestep:     6834 / 20000At timestep:     7035 / 20000At timestep:     7236 / 20000At timestep:     7437 / 20000At timestep:     7638 / 20000At timestep:     7839 / 20000At timestep:     8040 / 20000At timestep:     8241 / 20000At timestep:     8442 / 20000At timestep:     8643 / 20000At timestep:     8844 / 20000At timestep:     9045 / 20000At timestep:     9246 / 20000At timestep:     9447 / 20000At timestep:     9648 / 20000At timestep:     9849 / 20000At timestep:     10050 / 20000At timestep:     10251 / 20000At timestep:     10452 / 20000At timestep:     10653 / 20000At timestep:     10854 / 20000At timestep:     11055 / 20000At timestep:     11256 / 20000At timestep:     11457 / 20000At timestep:     11658 / 20000At timestep:     11859 / 20000At timestep:     12060 / 20000At timestep:     12261 / 20000At timestep:     12462 / 20000At timestep:     12663 / 20000At timestep:     12864 / 20000At timestep:     13065 / 20000At timestep:     13266 / 20000At timestep:     13467 / 20000At timestep:     13668 / 20000At timestep:     13869 / 20000At timestep:     14070 / 20000At timestep:     14271 / 20000At timestep:     14472 / 20000At timestep:     14673 / 20000At timestep:     14874 / 20000At timestep:     15075 / 20000At timestep:     15276 / 20000At timestep:     15477 / 20000At timestep:     15678 / 20000At timestep:     15879 / 20000At timestep:     16080 / 20000At timestep:     16281 / 20000At timestep:     16482 / 20000At timestep:     16683 / 20000At timestep:     16884 / 20000At timestep:     17085 / 20000At timestep:     17286 / 20000At timestep:     17487 / 20000At timestep:     17688 / 20000At timestep:     17889 / 20000At timestep:     18090 / 20000At timestep:     18291 / 20000At timestep:     18492 / 20000At timestep:     18693 / 20000At timestep:     18894 / 20000At timestep:     19095 / 20000At timestep:     19296 / 20000At timestep:     19497 / 20000At timestep:     19698 / 20000At timestep:     19899 / 20000At timestep:     20100 / 20000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -483.9980163574219
Eval_StdReturn : 42.781646728515625
Eval_MaxReturn : -441.21636962890625
Eval_MinReturn : -526.7796630859375
Eval_AverageEpLen : 201.0
Train_AverageReturn : -1887.0548095703125
Train_StdReturn : 400.1144714355469
Train_MaxReturn : -957.108154296875
Train_MinReturn : -2589.48681640625
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 20100
TimeSinceStart : 38.61594104766846
Training Loss : 0.19861221313476562
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -373.14532470703125
Eval_StdReturn : 17.617156982421875
Eval_MaxReturn : -355.5281677246094
Eval_MinReturn : -390.7624816894531
Eval_AverageEpLen : 201.0
Train_AverageReturn : -477.7079162597656
Train_StdReturn : 53.820892333984375
Train_MaxReturn : -392.1074523925781
Train_MinReturn : -539.567138671875
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 20904
TimeSinceStart : 128.41020822525024
Training Loss : 0.18447403609752655
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 2 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -331.93841552734375
Eval_StdReturn : 11.895034790039062
Eval_MaxReturn : -320.0433654785156
Eval_MinReturn : -343.83343505859375
Eval_AverageEpLen : 201.0
Train_AverageReturn : -376.3140563964844
Train_StdReturn : 19.28889274597168
Train_MaxReturn : -354.96173095703125
Train_MinReturn : -404.4768371582031
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 21708
TimeSinceStart : 218.72960805892944
Training Loss : 0.18065659701824188
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 3 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -335.3168029785156
Eval_StdReturn : 13.846038818359375
Eval_MaxReturn : -321.47076416015625
Eval_MinReturn : -349.162841796875
Eval_AverageEpLen : 201.0
Train_AverageReturn : -360.05987548828125
Train_StdReturn : 19.5634765625
Train_MaxReturn : -337.7358703613281
Train_MinReturn : -388.96405029296875
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 22512
TimeSinceStart : 309.6637465953827
Training Loss : 0.17307032644748688
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 4 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -336.965576171875
Eval_StdReturn : 3.621917724609375
Eval_MaxReturn : -333.3436584472656
Eval_MinReturn : -340.5874938964844
Eval_AverageEpLen : 201.0
Train_AverageReturn : -387.43316650390625
Train_StdReturn : 36.42642593383789
Train_MaxReturn : -351.9251403808594
Train_MinReturn : -442.95452880859375
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 23316
TimeSinceStart : 402.0424129962921
Training Loss : 0.17115987837314606
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 5 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -378.0705261230469
Eval_StdReturn : 11.11566162109375
Eval_MaxReturn : -366.9548645019531
Eval_MinReturn : -389.1861877441406
Eval_AverageEpLen : 201.0
Train_AverageReturn : -365.580810546875
Train_StdReturn : 18.757587432861328/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/core.py:257: DeprecationWarning: [33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.[0m
  "Function `env.seed(seed)` is marked as deprecated and will be removed in the future. "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  "Core environment is written in old step API which returns one bool instead of two. "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:235: UserWarning: [33mWARN: Expects `done` signal to be a boolean, actual type: <class 'numpy.float64'>[0m
  f"Expects `done` signal to be a boolean, actual type: {type(done)}"

Train_MaxReturn : -337.379638671875
Train_MinReturn : -388.62554931640625
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 24120
TimeSinceStart : 494.14727783203125
Training Loss : 0.16844065487384796
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 6 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -363.40106201171875
Eval_StdReturn : 9.874420166015625
Eval_MaxReturn : -353.5266418457031
Eval_MinReturn : -373.2754821777344
Eval_AverageEpLen : 201.0
Train_AverageReturn : -352.4079895019531
Train_StdReturn : 8.320479393005371
Train_MaxReturn : -344.2575988769531
Train_MinReturn : -363.5437927246094
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 24924
TimeSinceStart : 586.255300283432
Training Loss : 0.16209498047828674
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 7 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -370.3210144042969
Eval_StdReturn : 23.593505859375
Eval_MaxReturn : -346.7275085449219
Eval_MinReturn : -393.9145202636719
Eval_AverageEpLen : 201.0
Train_AverageReturn : -352.2200622558594
Train_StdReturn : 10.585489273071289
Train_MaxReturn : -340.4051513671875
Train_MinReturn : -366.0721740722656
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 25728
TimeSinceStart : 678.4839441776276
Training Loss : 0.16084711253643036
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 8 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -326.515625
Eval_StdReturn : 15.147506713867188
Eval_MaxReturn : -311.36810302734375
Eval_MinReturn : -341.6631164550781
Eval_AverageEpLen : 201.0
Train_AverageReturn : -348.2148132324219
Train_StdReturn : 25.94967269897461
Train_MaxReturn : -321.277099609375
Train_MinReturn : -383.6705627441406
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 26532
TimeSinceStart : 769.2011535167694
Training Loss : 0.16164271533489227
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 9 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -334.0927429199219
Eval_StdReturn : 16.573638916015625
Eval_MaxReturn : -317.51910400390625
Eval_MinReturn : -350.6663818359375
Eval_AverageEpLen : 201.0
Train_AverageReturn : -372.0042419433594
Train_StdReturn : 33.83765411376953
Train_MaxReturn : -329.1898498535156
Train_MinReturn : -422.55548095703125
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 27336
TimeSinceStart : 859.6238415241241
Training Loss : 0.16073429584503174
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 10 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -342.7311096191406
Eval_StdReturn : 24.288055419921875
Eval_MaxReturn : -318.44305419921875
Eval_MinReturn : -367.0191650390625
Eval_AverageEpLen : 201.0
Train_AverageReturn : -339.8892822265625
Train_StdReturn : 27.002498626708984
Train_MaxReturn : -301.02801513671875
Train_MinReturn : -369.40997314453125
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 28140
TimeSinceStart : 950.419949054718
Training Loss : 0.15936513245105743
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 11 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -342.1639709472656
Eval_StdReturn : 15.687347412109375
Eval_MaxReturn : -326.47662353515625
Eval_MinReturn : -357.851318359375
Eval_AverageEpLen : 201.0
Train_AverageReturn : -353.5358581542969
Train_StdReturn : 21.662006378173828
Train_MaxReturn : -321.1414794921875
Train_MinReturn : -375.97271728515625
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 28944
TimeSinceStart : 1041.6583812236786
Training Loss : 0.15515460073947906
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 12 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -328.6185607910156
Eval_StdReturn : 6.308746337890625
Eval_MaxReturn : -322.309814453125
Eval_MinReturn : -334.92730712890625
Eval_AverageEpLen : 201.0
Train_AverageReturn : -363.6397399902344
Train_StdReturn : 26.8668155670166
Train_MaxReturn : -318.55438232421875
Train_MinReturn : -389.1285400390625
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 29748
TimeSinceStart : 1132.6281039714813
Training Loss : 0.15317924320697784
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 13 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -358.1097412109375
Eval_StdReturn : 53.37373352050781
Eval_MaxReturn : -304.73602294921875
Eval_MinReturn : -411.4834899902344
Eval_AverageEpLen : 201.0
Train_AverageReturn : -349.718505859375
Train_StdReturn : 26.39948081970215
Train_MaxReturn : -311.1951599121094
Train_MinReturn : -378.29937744140625
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 30552
TimeSinceStart : 1224.0406336784363
Training Loss : 0.15502916276454926
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 14 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -359.5347900390625
Eval_StdReturn : 33.40663146972656
Eval_MaxReturn : -326.128173828125
Eval_MinReturn : -392.9414367675781
Eval_AverageEpLen : 201.0
Train_AverageReturn : -347.63623046875
Train_StdReturn : 24.342086791992188
Train_MaxReturn : -323.5455017089844
Train_MinReturn : -388.17889404296875
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 31356
TimeSinceStart : 1315.443015575409
Training Loss : 0.1531791239976883
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...





LOGGING TO:  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q4_reacher_numseq100_reacher-cs285-v0_02-11-2022_21-17-09 



########################
logging outputs to  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q4_reacher_numseq100_reacher-cs285-v0_02-11-2022_21-17-09
########################
Using GPU id 0
Using action sampling strategy: random


********** Iteration 0 ************

Collecting data to be used for training...
At timestep:     201 / 20000At timestep:     402 / 20000At timestep:     603 / 20000At timestep:     804 / 20000At timestep:     1005 / 20000At timestep:     1206 / 20000At timestep:     1407 / 20000At timestep:     1608 / 20000At timestep:     1809 / 20000At timestep:     2010 / 20000At timestep:     2211 / 20000At timestep:     2412 / 20000At timestep:     2613 / 20000At timestep:     2814 / 20000At timestep:     3015 / 20000At timestep:     3216 / 20000At timestep:     3417 / 20000At timestep:     3618 / 20000At timestep:     3819 / 20000At timestep:     4020 / 20000At timestep:     4221 / 20000At timestep:     4422 / 20000At timestep:     4623 / 20000At timestep:     4824 / 20000At timestep:     5025 / 20000At timestep:     5226 / 20000At timestep:     5427 / 20000At timestep:     5628 / 20000At timestep:     5829 / 20000At timestep:     6030 / 20000At timestep:     6231 / 20000At timestep:     6432 / 20000At timestep:     6633 / 20000At timestep:     6834 / 20000At timestep:     7035 / 20000At timestep:     7236 / 20000At timestep:     7437 / 20000At timestep:     7638 / 20000At timestep:     7839 / 20000At timestep:     8040 / 20000At timestep:     8241 / 20000At timestep:     8442 / 20000At timestep:     8643 / 20000At timestep:     8844 / 20000At timestep:     9045 / 20000At timestep:     9246 / 20000At timestep:     9447 / 20000At timestep:     9648 / 20000At timestep:     9849 / 20000At timestep:     10050 / 20000At timestep:     10251 / 20000At timestep:     10452 / 20000At timestep:     10653 / 20000At timestep:     10854 / 20000At timestep:     11055 / 20000At timestep:     11256 / 20000At timestep:     11457 / 20000At timestep:     11658 / 20000At timestep:     11859 / 20000At timestep:     12060 / 20000At timestep:     12261 / 20000At timestep:     12462 / 20000At timestep:     12663 / 20000At timestep:     12864 / 20000At timestep:     13065 / 20000At timestep:     13266 / 20000At timestep:     13467 / 20000At timestep:     13668 / 20000At timestep:     13869 / 20000At timestep:     14070 / 20000At timestep:     14271 / 20000At timestep:     14472 / 20000At timestep:     14673 / 20000At timestep:     14874 / 20000At timestep:     15075 / 20000At timestep:     15276 / 20000At timestep:     15477 / 20000At timestep:     15678 / 20000At timestep:     15879 / 20000At timestep:     16080 / 20000At timestep:     16281 / 20000At timestep:     16482 / 20000At timestep:     16683 / 20000At timestep:     16884 / 20000At timestep:     17085 / 20000At timestep:     17286 / 20000At timestep:     17487 / 20000At timestep:     17688 / 20000At timestep:     17889 / 20000At timestep:     18090 / 20000At timestep:     18291 / 20000At timestep:     18492 / 20000At timestep:     18693 / 20000At timestep:     18894 / 20000At timestep:     19095 / 20000At timestep:     19296 / 20000At timestep:     19497 / 20000At timestep:     19698 / 20000At timestep:     19899 / 20000At timestep:     20100 / 20000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -548.3797607421875
Eval_StdReturn : 73.78628540039062
Eval_MaxReturn : -474.593505859375
Eval_MinReturn : -622.1660766601562
Eval_AverageEpLen : 201.0
Train_AverageReturn : -1887.0548095703125
Train_StdReturn : 400.1144714355469
Train_MaxReturn : -957.108154296875
Train_MinReturn : -2589.48681640625
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 20100
TimeSinceStart : 18.18893599510193
Training Loss : 0.19861221313476562
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -340.5464782714844
Eval_StdReturn : 23.934967041015625
Eval_MaxReturn : -316.61151123046875
Eval_MinReturn : -364.4814453125
Eval_AverageEpLen : 201.0
Train_AverageReturn : -506.7595520019531
Train_StdReturn : 72.16397857666016
Train_MaxReturn : -437.6850280761719
Train_MinReturn : -626.6473999023438
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 20904
TimeSinceStart : 45.09810423851013
Training Loss : 0.18407964706420898
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 2 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -300.328369140625
Eval_StdReturn : 4.983978271484375
Eval_MaxReturn : -295.3443908691406
Eval_MinReturn : -305.3123474121094
Eval_AverageEpLen : 201.0
Train_AverageReturn : -325.47027587890625
Train_StdReturn : 18.691511154174805
Train_MaxReturn : -301.15509033203125
Train_MinReturn : -347.9338073730469
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 21708
TimeSinceStart : 71.89512133598328
Training Loss : 0.17709492146968842
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 3 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -329.2984619140625
Eval_StdReturn : 2.7956390380859375
Eval_MaxReturn : -326.5028381347656
Eval_MinReturn : -332.0941162109375
Eval_AverageEpLen : 201.0
Train_AverageReturn : -297.78717041015625
Train_StdReturn : 11.262210845947266
Train_MaxReturn : -282.0850524902344
Train_MinReturn : -308.6077575683594
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 22512
TimeSinceStart : 97.78640341758728
Training Loss : 0.17293070256710052
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 4 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -312.55859375
Eval_StdReturn : 13.633331298828125
Eval_MaxReturn : -298.9252624511719
Eval_MinReturn : -326.1919250488281
Eval_AverageEpLen : 201.0
Train_AverageReturn : -341.75775146484375
Train_StdReturn : 13.663044929504395
Train_MaxReturn : -330.8144836425781
Train_MinReturn : -365.17681884765625
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 23316
TimeSinceStart : 123.4159243106842
Training Loss : 0.1660977303981781
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 5 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -281.36572265625
Eval_StdReturn : 12.688949584960938
Eval_MaxReturn : -268.6767578125
Eval_MinReturn : -294.0546569824219
Eval_AverageEpLen : 201.0
Train_AverageReturn : -286.3264465332031
Train_StdReturn : 10.519094467163086
Train_MaxReturn : -269.6172790527344/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/core.py:257: DeprecationWarning: [33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.[0m
  "Function `env.seed(seed)` is marked as deprecated and will be removed in the future. "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  "Core environment is written in old step API which returns one bool instead of two. "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:235: UserWarning: [33mWARN: Expects `done` signal to be a boolean, actual type: <class 'numpy.float64'>[0m
  f"Expects `done` signal to be a boolean, actual type: {type(done)}"

Train_MinReturn : -298.73455810546875
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 24120
TimeSinceStart : 149.02908444404602
Training Loss : 0.16959768533706665
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 6 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -360.3459777832031
Eval_StdReturn : 59.204620361328125
Eval_MaxReturn : -301.141357421875
Eval_MinReturn : -419.55059814453125
Eval_AverageEpLen : 201.0
Train_AverageReturn : -306.13665771484375
Train_StdReturn : 21.002607345581055
Train_MaxReturn : -282.8687438964844
Train_MinReturn : -338.35504150390625
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 24924
TimeSinceStart : 174.5105803012848
Training Loss : 0.16456568241119385
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 7 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -325.741943359375
Eval_StdReturn : 2.229888916015625
Eval_MaxReturn : -323.5120544433594
Eval_MinReturn : -327.9718322753906
Eval_AverageEpLen : 201.0
Train_AverageReturn : -320.5113525390625
Train_StdReturn : 14.788642883300781
Train_MaxReturn : -300.0975036621094
Train_MinReturn : -341.8140563964844
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 25728
TimeSinceStart : 199.97770833969116
Training Loss : 0.1630573272705078
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 8 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -307.36505126953125
Eval_StdReturn : 6.6138153076171875
Eval_MaxReturn : -300.751220703125
Eval_MinReturn : -313.9788513183594
Eval_AverageEpLen : 201.0
Train_AverageReturn : -314.1002197265625
Train_StdReturn : 20.643817901611328
Train_MaxReturn : -279.2838134765625
Train_MinReturn : -329.9300537109375
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 26532
TimeSinceStart : 225.56945180892944
Training Loss : 0.15837347507476807
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 9 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -308.78753662109375
Eval_StdReturn : 6.1916351318359375
Eval_MaxReturn : -302.59588623046875
Eval_MinReturn : -314.9791564941406
Eval_AverageEpLen : 201.0
Train_AverageReturn : -289.0177001953125
Train_StdReturn : 18.6612548828125
Train_MaxReturn : -261.9776611328125
Train_MinReturn : -314.3767395019531
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 27336
TimeSinceStart : 251.4804549217224
Training Loss : 0.1618361473083496
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 10 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -336.04046630859375
Eval_StdReturn : 14.996932983398438
Eval_MaxReturn : -321.0435485839844
Eval_MinReturn : -351.03741455078125
Eval_AverageEpLen : 201.0
Train_AverageReturn : -315.4168395996094
Train_StdReturn : 30.868574142456055
Train_MaxReturn : -273.14556884765625
Train_MinReturn : -356.3995056152344
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 28140
TimeSinceStart : 277.3198742866516
Training Loss : 0.15618829429149628
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 11 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -295.666748046875
Eval_StdReturn : 25.640838623046875
Eval_MaxReturn : -270.0259094238281
Eval_MinReturn : -321.3075866699219
Eval_AverageEpLen : 201.0
Train_AverageReturn : -325.2945556640625
Train_StdReturn : 20.180089950561523
Train_MaxReturn : -302.14959716796875
Train_MinReturn : -347.5390930175781
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 28944
TimeSinceStart : 303.2113959789276
Training Loss : 0.15354378521442413
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 12 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -305.746826171875
Eval_StdReturn : 3.6989593505859375
Eval_MaxReturn : -302.0478820800781
Eval_MinReturn : -309.44580078125
Eval_AverageEpLen : 201.0
Train_AverageReturn : -318.447021484375
Train_StdReturn : 31.850204467773438
Train_MaxReturn : -267.588623046875
Train_MinReturn : -355.2171630859375
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 29748
TimeSinceStart : 329.5964026451111
Training Loss : 0.1526527851819992
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 13 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -297.73577880859375
Eval_StdReturn : 12.445816040039062
Eval_MaxReturn : -285.28997802734375
Eval_MinReturn : -310.1816101074219
Eval_AverageEpLen : 201.0
Train_AverageReturn : -313.11419677734375
Train_StdReturn : 10.852021217346191
Train_MaxReturn : -296.6854248046875
Train_MinReturn : -325.55902099609375
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 30552
TimeSinceStart : 355.52318835258484
Training Loss : 0.15080727636814117
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 14 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -342.11541748046875
Eval_StdReturn : 5.0215301513671875
Eval_MaxReturn : -337.0938720703125
Eval_MinReturn : -347.1369323730469
Eval_AverageEpLen : 201.0
Train_AverageReturn : -312.0648498535156
Train_StdReturn : 25.74793243408203
Train_MaxReturn : -279.12884521484375
Train_MinReturn : -344.5595397949219
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 31356
TimeSinceStart : 381.2136650085449
Training Loss : 0.15283961594104767
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...





LOGGING TO:  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q4_reacher_numseq1000_reacher-cs285-v0_02-11-2022_21-23-34 



########################
logging outputs to  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q4_reacher_numseq1000_reacher-cs285-v0_02-11-2022_21-23-34
########################
Using GPU id 0
Using action sampling strategy: random


********** Iteration 0 ************

Collecting data to be used for training...
At timestep:     201 / 20000At timestep:     402 / 20000At timestep:     603 / 20000At timestep:     804 / 20000At timestep:     1005 / 20000At timestep:     1206 / 20000At timestep:     1407 / 20000At timestep:     1608 / 20000At timestep:     1809 / 20000At timestep:     2010 / 20000At timestep:     2211 / 20000At timestep:     2412 / 20000At timestep:     2613 / 20000At timestep:     2814 / 20000At timestep:     3015 / 20000At timestep:     3216 / 20000At timestep:     3417 / 20000At timestep:     3618 / 20000At timestep:     3819 / 20000At timestep:     4020 / 20000At timestep:     4221 / 20000At timestep:     4422 / 20000At timestep:     4623 / 20000At timestep:     4824 / 20000At timestep:     5025 / 20000At timestep:     5226 / 20000At timestep:     5427 / 20000At timestep:     5628 / 20000At timestep:     5829 / 20000At timestep:     6030 / 20000At timestep:     6231 / 20000At timestep:     6432 / 20000At timestep:     6633 / 20000At timestep:     6834 / 20000At timestep:     7035 / 20000At timestep:     7236 / 20000At timestep:     7437 / 20000At timestep:     7638 / 20000At timestep:     7839 / 20000At timestep:     8040 / 20000At timestep:     8241 / 20000At timestep:     8442 / 20000At timestep:     8643 / 20000At timestep:     8844 / 20000At timestep:     9045 / 20000At timestep:     9246 / 20000At timestep:     9447 / 20000At timestep:     9648 / 20000At timestep:     9849 / 20000At timestep:     10050 / 20000At timestep:     10251 / 20000At timestep:     10452 / 20000At timestep:     10653 / 20000At timestep:     10854 / 20000At timestep:     11055 / 20000At timestep:     11256 / 20000At timestep:     11457 / 20000At timestep:     11658 / 20000At timestep:     11859 / 20000At timestep:     12060 / 20000At timestep:     12261 / 20000At timestep:     12462 / 20000At timestep:     12663 / 20000At timestep:     12864 / 20000At timestep:     13065 / 20000At timestep:     13266 / 20000At timestep:     13467 / 20000At timestep:     13668 / 20000At timestep:     13869 / 20000At timestep:     14070 / 20000At timestep:     14271 / 20000At timestep:     14472 / 20000At timestep:     14673 / 20000At timestep:     14874 / 20000At timestep:     15075 / 20000At timestep:     15276 / 20000At timestep:     15477 / 20000At timestep:     15678 / 20000At timestep:     15879 / 20000At timestep:     16080 / 20000At timestep:     16281 / 20000At timestep:     16482 / 20000At timestep:     16683 / 20000At timestep:     16884 / 20000At timestep:     17085 / 20000At timestep:     17286 / 20000At timestep:     17487 / 20000At timestep:     17688 / 20000At timestep:     17889 / 20000At timestep:     18090 / 20000At timestep:     18291 / 20000At timestep:     18492 / 20000At timestep:     18693 / 20000At timestep:     18894 / 20000At timestep:     19095 / 20000At timestep:     19296 / 20000At timestep:     19497 / 20000At timestep:     19698 / 20000At timestep:     19899 / 20000At timestep:     20100 / 20000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -530.2503662109375
Eval_StdReturn : 54.960845947265625
Eval_MaxReturn : -475.28948974609375
Eval_MinReturn : -585.211181640625
Eval_AverageEpLen : 201.0
Train_AverageReturn : -1887.0548095703125
Train_StdReturn : 400.1144714355469
Train_MaxReturn : -957.108154296875
Train_MinReturn : -2589.48681640625
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 20100
TimeSinceStart : 19.943870306015015
Training Loss : 0.19861221313476562
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -317.0001220703125
Eval_StdReturn : 23.155838012695312
Eval_MaxReturn : -293.84429931640625
Eval_MinReturn : -340.1559753417969
Eval_AverageEpLen : 201.0
Train_AverageReturn : -537.6845092773438
Train_StdReturn : 67.76766967773438
Train_MaxReturn : -473.7204895019531
Train_MinReturn : -645.3765869140625
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 20904
TimeSinceStart : 53.565022230148315
Training Loss : 0.1931399703025818
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 2 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -270.84466552734375
Eval_StdReturn : 2.5448150634765625
Eval_MaxReturn : -268.29986572265625
Eval_MinReturn : -273.3894958496094
Eval_AverageEpLen : 201.0
Train_AverageReturn : -294.62957763671875
Train_StdReturn : 5.179706573486328
Train_MaxReturn : -285.8984069824219
Train_MinReturn : -299.4845886230469
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 21708
TimeSinceStart : 86.90785336494446
Training Loss : 0.1731197088956833
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 3 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -286.7525634765625
Eval_StdReturn : 3.95196533203125
Eval_MaxReturn : -282.80059814453125
Eval_MinReturn : -290.70452880859375
Eval_AverageEpLen : 201.0
Train_AverageReturn : -273.8682861328125
Train_StdReturn : 12.298580169677734
Train_MaxReturn : -260.4909362792969
Train_MinReturn : -288.7041320800781
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 22512
TimeSinceStart : 120.62374472618103
Training Loss : 0.17274922132492065
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 4 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -265.84912109375
Eval_StdReturn : 0.8331298828125
Eval_MaxReturn : -265.0159912109375
Eval_MinReturn : -266.6822509765625
Eval_AverageEpLen : 201.0
Train_AverageReturn : -264.8193054199219
Train_StdReturn : 15.50151252746582
Train_MaxReturn : -244.99415588378906
Train_MinReturn : -287.33795166015625
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 23316
TimeSinceStart : 154.68018245697021
Training Loss : 0.1679692417383194
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 5 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -268.6229553222656
Eval_StdReturn : 13.143928527832031
Eval_MaxReturn : -255.47901916503906
Eval_MinReturn : -281.7668762207031
Eval_AverageEpLen : 201.0
Train_AverageReturn : -276.44683837890625
Train_StdReturn : 13.320639610290527/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/core.py:257: DeprecationWarning: [33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.[0m
  "Function `env.seed(seed)` is marked as deprecated and will be removed in the future. "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  "Core environment is written in old step API which returns one bool instead of two. "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:235: UserWarning: [33mWARN: Expects `done` signal to be a boolean, actual type: <class 'numpy.float64'>[0m
  f"Expects `done` signal to be a boolean, actual type: {type(done)}"

Train_MaxReturn : -259.74444580078125
Train_MinReturn : -291.7901306152344
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 24120
TimeSinceStart : 188.7287769317627
Training Loss : 0.16865132749080658
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 6 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -278.9810791015625
Eval_StdReturn : 13.957839965820312
Eval_MaxReturn : -265.0232238769531
Eval_MinReturn : -292.93890380859375
Eval_AverageEpLen : 201.0
Train_AverageReturn : -261.3548583984375
Train_StdReturn : 8.610754013061523
Train_MaxReturn : -250.8925018310547
Train_MinReturn : -272.59063720703125
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 24924
TimeSinceStart : 222.72961902618408
Training Loss : 0.16564945876598358
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 7 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -259.8836364746094
Eval_StdReturn : 20.548858642578125
Eval_MaxReturn : -239.33477783203125
Eval_MinReturn : -280.4324951171875
Eval_AverageEpLen : 201.0
Train_AverageReturn : -267.40838623046875
Train_StdReturn : 10.655119895935059
Train_MaxReturn : -249.08905029296875
Train_MinReturn : -275.2143859863281
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 25728
TimeSinceStart : 257.95169830322266
Training Loss : 0.16521219909191132
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 8 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -272.6877746582031
Eval_StdReturn : 2.715606689453125
Eval_MaxReturn : -269.97216796875
Eval_MinReturn : -275.40338134765625
Eval_AverageEpLen : 201.0
Train_AverageReturn : -299.19097900390625
Train_StdReturn : 36.98207092285156
Train_MaxReturn : -253.65008544921875
Train_MinReturn : -339.4585266113281
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 26532
TimeSinceStart : 293.3762104511261
Training Loss : 0.15866582095623016
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 9 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -258.20458984375
Eval_StdReturn : 7.4767303466796875
Eval_MaxReturn : -250.72784423828125
Eval_MinReturn : -265.6813049316406
Eval_AverageEpLen : 201.0
Train_AverageReturn : -269.3595275878906
Train_StdReturn : 7.059474945068359
Train_MaxReturn : -262.1835021972656
Train_MinReturn : -276.4802551269531
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 27336
TimeSinceStart : 327.81035447120667
Training Loss : 0.1616498827934265
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 10 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -296.89556884765625
Eval_StdReturn : 25.664642333984375
Eval_MaxReturn : -271.2309265136719
Eval_MinReturn : -322.5602111816406
Eval_AverageEpLen : 201.0
Train_AverageReturn : -261.3101501464844
Train_StdReturn : 15.11253547668457
Train_MaxReturn : -247.57574462890625
Train_MinReturn : -285.4844055175781
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 28140
TimeSinceStart : 361.7885797023773
Training Loss : 0.1554473638534546
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 11 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -284.3224792480469
Eval_StdReturn : 5.794891357421875
Eval_MaxReturn : -278.527587890625
Eval_MinReturn : -290.11737060546875
Eval_AverageEpLen : 201.0
Train_AverageReturn : -249.93511962890625
Train_StdReturn : 8.418220520019531
Train_MaxReturn : -236.8280029296875
Train_MinReturn : -260.0191955566406
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 28944
TimeSinceStart : 395.96712160110474
Training Loss : 0.15328046679496765
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 12 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -254.8817138671875
Eval_StdReturn : 1.6114425659179688
Eval_MaxReturn : -253.27027893066406
Eval_MinReturn : -256.4931640625
Eval_AverageEpLen : 201.0
Train_AverageReturn : -270.0320739746094
Train_StdReturn : 11.585246086120605
Train_MaxReturn : -258.54156494140625
Train_MinReturn : -287.05682373046875
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 29748
TimeSinceStart : 430.37503123283386
Training Loss : 0.15252582728862762
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 13 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -231.3693084716797
Eval_StdReturn : 6.2331695556640625
Eval_MaxReturn : -225.13613891601562
Eval_MinReturn : -237.60247802734375
Eval_AverageEpLen : 201.0
Train_AverageReturn : -272.7889099121094
Train_StdReturn : 8.14840316772461
Train_MaxReturn : -261.22900390625
Train_MinReturn : -283.2556457519531
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 30552
TimeSinceStart : 464.8173496723175
Training Loss : 0.15008573234081268
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 14 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -275.8951721191406
Eval_StdReturn : 4.85272216796875
Eval_MaxReturn : -271.0424499511719
Eval_MinReturn : -280.7478942871094
Eval_AverageEpLen : 201.0
Train_AverageReturn : -264.60595703125
Train_StdReturn : 11.915542602539062
Train_MaxReturn : -248.3751220703125
Train_MinReturn : -281.6749572753906
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 31356
TimeSinceStart : 499.25286960601807
Training Loss : 0.15264248847961426
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...





LOGGING TO:  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q4_reacher_ensemble1_reacher-cs285-v0_02-11-2022_21-31-56 



########################
logging outputs to  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q4_reacher_ensemble1_reacher-cs285-v0_02-11-2022_21-31-56
########################
Using GPU id 0
Using action sampling strategy: random


********** Iteration 0 ************

Collecting data to be used for training...
At timestep:     201 / 20000At timestep:     402 / 20000At timestep:     603 / 20000At timestep:     804 / 20000At timestep:     1005 / 20000At timestep:     1206 / 20000At timestep:     1407 / 20000At timestep:     1608 / 20000At timestep:     1809 / 20000At timestep:     2010 / 20000At timestep:     2211 / 20000At timestep:     2412 / 20000At timestep:     2613 / 20000At timestep:     2814 / 20000At timestep:     3015 / 20000At timestep:     3216 / 20000At timestep:     3417 / 20000At timestep:     3618 / 20000At timestep:     3819 / 20000At timestep:     4020 / 20000At timestep:     4221 / 20000At timestep:     4422 / 20000At timestep:     4623 / 20000At timestep:     4824 / 20000At timestep:     5025 / 20000At timestep:     5226 / 20000At timestep:     5427 / 20000At timestep:     5628 / 20000At timestep:     5829 / 20000At timestep:     6030 / 20000At timestep:     6231 / 20000At timestep:     6432 / 20000At timestep:     6633 / 20000At timestep:     6834 / 20000At timestep:     7035 / 20000At timestep:     7236 / 20000At timestep:     7437 / 20000At timestep:     7638 / 20000At timestep:     7839 / 20000At timestep:     8040 / 20000At timestep:     8241 / 20000At timestep:     8442 / 20000At timestep:     8643 / 20000At timestep:     8844 / 20000At timestep:     9045 / 20000At timestep:     9246 / 20000At timestep:     9447 / 20000At timestep:     9648 / 20000At timestep:     9849 / 20000At timestep:     10050 / 20000At timestep:     10251 / 20000At timestep:     10452 / 20000At timestep:     10653 / 20000At timestep:     10854 / 20000At timestep:     11055 / 20000At timestep:     11256 / 20000At timestep:     11457 / 20000At timestep:     11658 / 20000At timestep:     11859 / 20000At timestep:     12060 / 20000At timestep:     12261 / 20000At timestep:     12462 / 20000At timestep:     12663 / 20000At timestep:     12864 / 20000At timestep:     13065 / 20000At timestep:     13266 / 20000At timestep:     13467 / 20000At timestep:     13668 / 20000At timestep:     13869 / 20000At timestep:     14070 / 20000At timestep:     14271 / 20000At timestep:     14472 / 20000At timestep:     14673 / 20000At timestep:     14874 / 20000At timestep:     15075 / 20000At timestep:     15276 / 20000At timestep:     15477 / 20000At timestep:     15678 / 20000At timestep:     15879 / 20000At timestep:     16080 / 20000At timestep:     16281 / 20000At timestep:     16482 / 20000At timestep:     16683 / 20000At timestep:     16884 / 20000At timestep:     17085 / 20000At timestep:     17286 / 20000At timestep:     17487 / 20000At timestep:     17688 / 20000At timestep:     17889 / 20000At timestep:     18090 / 20000At timestep:     18291 / 20000At timestep:     18492 / 20000At timestep:     18693 / 20000At timestep:     18894 / 20000At timestep:     19095 / 20000At timestep:     19296 / 20000At timestep:     19497 / 20000At timestep:     19698 / 20000At timestep:     19899 / 20000At timestep:     20100 / 20000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -453.934814453125
Eval_StdReturn : 40.898284912109375
Eval_MaxReturn : -413.0365295410156
Eval_MinReturn : -494.8330993652344
Eval_AverageEpLen : 201.0
Train_AverageReturn : -1887.0548095703125
Train_StdReturn : 400.1144714355469
Train_MaxReturn : -957.108154296875
Train_MinReturn : -2589.48681640625
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 20100
TimeSinceStart : 11.071821212768555
Training Loss : 0.1967788189649582
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -339.3973693847656
Eval_StdReturn : 39.12664794921875
Eval_MaxReturn : -300.2707214355469
Eval_MinReturn : -378.5240173339844
Eval_AverageEpLen : 201.0
Train_AverageReturn : -481.12237548828125
Train_StdReturn : 70.32246398925781
Train_MaxReturn : -386.0088195800781
Train_MinReturn : -552.130126953125
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 20904
TimeSinceStart : 24.325235843658447
Training Loss : 0.18762491643428802
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 2 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -285.0455017089844
Eval_StdReturn : 17.340545654296875
Eval_MaxReturn : -267.7049560546875
Eval_MinReturn : -302.38604736328125
Eval_AverageEpLen : 201.0
Train_AverageReturn : -280.6407470703125
Train_StdReturn : 8.993047714233398
Train_MaxReturn : -266.4940185546875
Train_MinReturn : -288.496826171875
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 21708
TimeSinceStart : 37.78815960884094
Training Loss : 0.1703185886144638
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 3 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -257.97613525390625
Eval_StdReturn : 2.0893630981445312
Eval_MaxReturn : -255.8867645263672
Eval_MinReturn : -260.06549072265625
Eval_AverageEpLen : 201.0
Train_AverageReturn : -286.6212463378906
Train_StdReturn : 24.852128982543945
Train_MaxReturn : -262.302490234375
Train_MinReturn : -327.7827453613281
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 22512
TimeSinceStart : 51.084657192230225
Training Loss : 0.16653619706630707
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 4 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -274.4142761230469
Eval_StdReturn : 8.940887451171875
Eval_MaxReturn : -265.473388671875
Eval_MinReturn : -283.35516357421875
Eval_AverageEpLen : 201.0
Train_AverageReturn : -268.43048095703125
Train_StdReturn : 9.938462257385254
Train_MaxReturn : -260.6672668457031
Train_MinReturn : -285.3919677734375
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 23316
TimeSinceStart : 64.30826783180237
Training Loss : 0.1723308563232422
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 5 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -326.5880126953125
Eval_StdReturn : 37.24839782714844
Eval_MaxReturn : -289.3396301269531
Eval_MinReturn : -363.83642578125
Eval_AverageEpLen : 201.0
Train_AverageReturn : -268.4146423339844
Train_StdReturn : 2.74979567527771
Train_MaxReturn : -265.49017333984375/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/core.py:257: DeprecationWarning: [33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.[0m
  "Function `env.seed(seed)` is marked as deprecated and will be removed in the future. "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  "Core environment is written in old step API which returns one bool instead of two. "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:235: UserWarning: [33mWARN: Expects `done` signal to be a boolean, actual type: <class 'numpy.float64'>[0m
  f"Expects `done` signal to be a boolean, actual type: {type(done)}"

Train_MinReturn : -272.715087890625
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 24120
TimeSinceStart : 77.56339597702026
Training Loss : 0.1675652712583542
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 6 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -272.54644775390625
Eval_StdReturn : 14.274765014648438
Eval_MaxReturn : -258.2716979980469
Eval_MinReturn : -286.82122802734375
Eval_AverageEpLen : 201.0
Train_AverageReturn : -266.3370666503906
Train_StdReturn : 30.23863410949707
Train_MaxReturn : -245.34034729003906
Train_MinReturn : -318.5318908691406
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 24924
TimeSinceStart : 90.78962540626526
Training Loss : 0.1580834686756134
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 7 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -283.93328857421875
Eval_StdReturn : 21.308700561523438
Eval_MaxReturn : -262.6246032714844
Eval_MinReturn : -305.24200439453125
Eval_AverageEpLen : 201.0
Train_AverageReturn : -283.36676025390625
Train_StdReturn : 17.976154327392578
Train_MaxReturn : -260.3942565917969
Train_MinReturn : -310.19921875
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 25728
TimeSinceStart : 104.05153465270996
Training Loss : 0.15956702828407288
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 8 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -361.69189453125
Eval_StdReturn : 96.6669921875
Eval_MaxReturn : -265.02490234375
Eval_MinReturn : -458.35888671875
Eval_AverageEpLen : 201.0
Train_AverageReturn : -317.33697509765625
Train_StdReturn : 20.847850799560547
Train_MaxReturn : -291.4966125488281
Train_MinReturn : -349.1427307128906
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 26532
TimeSinceStart : 117.37857556343079
Training Loss : 0.16103079915046692
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 9 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -282.1352844238281
Eval_StdReturn : 10.48016357421875
Eval_MaxReturn : -271.6551208496094
Eval_MinReturn : -292.6154479980469
Eval_AverageEpLen : 201.0
Train_AverageReturn : -286.7669372558594
Train_StdReturn : 20.32037353515625
Train_MaxReturn : -264.4609069824219
Train_MinReturn : -318.91436767578125
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 27336
TimeSinceStart : 130.73691129684448
Training Loss : 0.15860700607299805
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 10 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -282.96319580078125
Eval_StdReturn : 4.8526458740234375
Eval_MaxReturn : -278.11053466796875
Eval_MinReturn : -287.8158264160156
Eval_AverageEpLen : 201.0
Train_AverageReturn : -273.94757080078125
Train_StdReturn : 14.277778625488281
Train_MaxReturn : -260.42510986328125
Train_MinReturn : -297.1911315917969
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 28140
TimeSinceStart : 144.1539170742035
Training Loss : 0.16259223222732544
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 11 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -270.93939208984375
Eval_StdReturn : 9.288467407226562
Eval_MaxReturn : -261.65093994140625
Eval_MinReturn : -280.2278747558594
Eval_AverageEpLen : 201.0
Train_AverageReturn : -266.1820068359375
Train_StdReturn : 5.544620513916016
Train_MaxReturn : -260.8888244628906
Train_MinReturn : -275.28875732421875
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 28944
TimeSinceStart : 157.5657548904419
Training Loss : 0.15564367175102234
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 12 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -264.30389404296875
Eval_StdReturn : 27.193893432617188
Eval_MaxReturn : -237.1099853515625
Eval_MinReturn : -291.4977722167969
Eval_AverageEpLen : 201.0
Train_AverageReturn : -286.2480773925781
Train_StdReturn : 22.881383895874023
Train_MaxReturn : -264.44775390625
Train_MinReturn : -323.5109558105469
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 29748
TimeSinceStart : 170.97537660598755
Training Loss : 0.15299104154109955
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 13 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -262.7003173828125
Eval_StdReturn : 1.0529327392578125
Eval_MaxReturn : -261.64739990234375
Eval_MinReturn : -263.7532653808594
Eval_AverageEpLen : 201.0
Train_AverageReturn : -273.1307678222656
Train_StdReturn : 8.013615608215332
Train_MaxReturn : -261.2954406738281
Train_MinReturn : -282.3766174316406
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 30552
TimeSinceStart : 184.47259521484375
Training Loss : 0.1532823145389557
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 14 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -291.76385498046875
Eval_StdReturn : 33.70458984375
Eval_MaxReturn : -258.05926513671875
Eval_MinReturn : -325.46844482421875
Eval_AverageEpLen : 201.0
Train_AverageReturn : -310.833251953125
Train_StdReturn : 50.649566650390625
Train_MaxReturn : -262.4406433105469
Train_MinReturn : -395.9406433105469
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 31356
TimeSinceStart : 197.96978425979614
Training Loss : 0.15687836706638336
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...





LOGGING TO:  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q4_reacher_ensemble3_reacher-cs285-v0_02-11-2022_21-35-18 



########################
logging outputs to  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q4_reacher_ensemble3_reacher-cs285-v0_02-11-2022_21-35-18
########################
Using GPU id 0
Using action sampling strategy: random


********** Iteration 0 ************

Collecting data to be used for training...
At timestep:     201 / 20000At timestep:     402 / 20000At timestep:     603 / 20000At timestep:     804 / 20000At timestep:     1005 / 20000At timestep:     1206 / 20000At timestep:     1407 / 20000At timestep:     1608 / 20000At timestep:     1809 / 20000At timestep:     2010 / 20000At timestep:     2211 / 20000At timestep:     2412 / 20000At timestep:     2613 / 20000At timestep:     2814 / 20000At timestep:     3015 / 20000At timestep:     3216 / 20000At timestep:     3417 / 20000At timestep:     3618 / 20000At timestep:     3819 / 20000At timestep:     4020 / 20000At timestep:     4221 / 20000At timestep:     4422 / 20000At timestep:     4623 / 20000At timestep:     4824 / 20000At timestep:     5025 / 20000At timestep:     5226 / 20000At timestep:     5427 / 20000At timestep:     5628 / 20000At timestep:     5829 / 20000At timestep:     6030 / 20000At timestep:     6231 / 20000At timestep:     6432 / 20000At timestep:     6633 / 20000At timestep:     6834 / 20000At timestep:     7035 / 20000At timestep:     7236 / 20000At timestep:     7437 / 20000At timestep:     7638 / 20000At timestep:     7839 / 20000At timestep:     8040 / 20000At timestep:     8241 / 20000At timestep:     8442 / 20000At timestep:     8643 / 20000At timestep:     8844 / 20000At timestep:     9045 / 20000At timestep:     9246 / 20000At timestep:     9447 / 20000At timestep:     9648 / 20000At timestep:     9849 / 20000At timestep:     10050 / 20000At timestep:     10251 / 20000At timestep:     10452 / 20000At timestep:     10653 / 20000At timestep:     10854 / 20000At timestep:     11055 / 20000At timestep:     11256 / 20000At timestep:     11457 / 20000At timestep:     11658 / 20000At timestep:     11859 / 20000At timestep:     12060 / 20000At timestep:     12261 / 20000At timestep:     12462 / 20000At timestep:     12663 / 20000At timestep:     12864 / 20000At timestep:     13065 / 20000At timestep:     13266 / 20000At timestep:     13467 / 20000At timestep:     13668 / 20000At timestep:     13869 / 20000At timestep:     14070 / 20000At timestep:     14271 / 20000At timestep:     14472 / 20000At timestep:     14673 / 20000At timestep:     14874 / 20000At timestep:     15075 / 20000At timestep:     15276 / 20000At timestep:     15477 / 20000At timestep:     15678 / 20000At timestep:     15879 / 20000At timestep:     16080 / 20000At timestep:     16281 / 20000At timestep:     16482 / 20000At timestep:     16683 / 20000At timestep:     16884 / 20000At timestep:     17085 / 20000At timestep:     17286 / 20000At timestep:     17487 / 20000At timestep:     17688 / 20000At timestep:     17889 / 20000At timestep:     18090 / 20000At timestep:     18291 / 20000At timestep:     18492 / 20000At timestep:     18693 / 20000At timestep:     18894 / 20000At timestep:     19095 / 20000At timestep:     19296 / 20000At timestep:     19497 / 20000At timestep:     19698 / 20000At timestep:     19899 / 20000At timestep:     20100 / 20000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -530.2503662109375
Eval_StdReturn : 54.960845947265625
Eval_MaxReturn : -475.28948974609375
Eval_MinReturn : -585.211181640625
Eval_AverageEpLen : 201.0
Train_AverageReturn : -1887.0548095703125
Train_StdReturn : 400.1144714355469
Train_MaxReturn : -957.108154296875
Train_MinReturn : -2589.48681640625
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 20100
TimeSinceStart : 21.323333024978638
Training Loss : 0.19861221313476562
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -317.0001220703125
Eval_StdReturn : 23.155838012695312
Eval_MaxReturn : -293.84429931640625
Eval_MinReturn : -340.1559753417969
Eval_AverageEpLen : 201.0
Train_AverageReturn : -537.6845092773438
Train_StdReturn : 67.76766967773438
Train_MaxReturn : -473.7204895019531
Train_MinReturn : -645.3765869140625
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 20904
TimeSinceStart : 57.11412262916565
Training Loss : 0.1931399703025818
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 2 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -270.84466552734375
Eval_StdReturn : 2.5448150634765625
Eval_MaxReturn : -268.29986572265625
Eval_MinReturn : -273.3894958496094
Eval_AverageEpLen : 201.0
Train_AverageReturn : -294.62957763671875
Train_StdReturn : 5.179706573486328
Train_MaxReturn : -285.8984069824219
Train_MinReturn : -299.4845886230469
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 21708
TimeSinceStart : 91.52622199058533
Training Loss : 0.1731197088956833
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 3 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -286.7525634765625
Eval_StdReturn : 3.95196533203125
Eval_MaxReturn : -282.80059814453125
Eval_MinReturn : -290.70452880859375
Eval_AverageEpLen : 201.0
Train_AverageReturn : -273.8682861328125
Train_StdReturn : 12.298580169677734
Train_MaxReturn : -260.4909362792969
Train_MinReturn : -288.7041320800781
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 22512
TimeSinceStart : 126.21183037757874
Training Loss : 0.17274922132492065
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 4 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -265.84912109375
Eval_StdReturn : 0.8331298828125
Eval_MaxReturn : -265.0159912109375
Eval_MinReturn : -266.6822509765625
Eval_AverageEpLen : 201.0
Train_AverageReturn : -264.8193054199219
Train_StdReturn : 15.50151252746582
Train_MaxReturn : -244.99415588378906
Train_MinReturn : -287.33795166015625
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 23316
TimeSinceStart : 162.29321193695068
Training Loss : 0.1679692417383194
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 5 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -268.6229553222656
Eval_StdReturn : 13.143928527832031
Eval_MaxReturn : -255.47901916503906
Eval_MinReturn : -281.7668762207031
Eval_AverageEpLen : 201.0
Train_AverageReturn : -276.44683837890625
Train_StdReturn : 13.320639610290527/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/core.py:257: DeprecationWarning: [33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.[0m
  "Function `env.seed(seed)` is marked as deprecated and will be removed in the future. "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  "Core environment is written in old step API which returns one bool instead of two. "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:235: UserWarning: [33mWARN: Expects `done` signal to be a boolean, actual type: <class 'numpy.float64'>[0m
  f"Expects `done` signal to be a boolean, actual type: {type(done)}"

Train_MaxReturn : -259.74444580078125
Train_MinReturn : -291.7901306152344
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 24120
TimeSinceStart : 197.033109664917
Training Loss : 0.16865132749080658
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 6 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -278.9810791015625
Eval_StdReturn : 13.957839965820312
Eval_MaxReturn : -265.0232238769531
Eval_MinReturn : -292.93890380859375
Eval_AverageEpLen : 201.0
Train_AverageReturn : -261.3548583984375
Train_StdReturn : 8.610754013061523
Train_MaxReturn : -250.8925018310547
Train_MinReturn : -272.59063720703125
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 24924
TimeSinceStart : 232.19414591789246
Training Loss : 0.16564945876598358
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 7 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -259.8836364746094
Eval_StdReturn : 20.548858642578125
Eval_MaxReturn : -239.33477783203125
Eval_MinReturn : -280.4324951171875
Eval_AverageEpLen : 201.0
Train_AverageReturn : -267.40838623046875
Train_StdReturn : 10.655119895935059
Train_MaxReturn : -249.08905029296875
Train_MinReturn : -275.2143859863281
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 25728
TimeSinceStart : 273.28963589668274
Training Loss : 0.16521219909191132
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 8 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -272.6877746582031
Eval_StdReturn : 2.715606689453125
Eval_MaxReturn : -269.97216796875
Eval_MinReturn : -275.40338134765625
Eval_AverageEpLen : 201.0
Train_AverageReturn : -299.19097900390625
Train_StdReturn : 36.98207092285156
Train_MaxReturn : -253.65008544921875
Train_MinReturn : -339.4585266113281
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 26532
TimeSinceStart : 310.7045867443085
Training Loss : 0.15866582095623016
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 9 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -258.20458984375
Eval_StdReturn : 7.4767303466796875
Eval_MaxReturn : -250.72784423828125
Eval_MinReturn : -265.6813049316406
Eval_AverageEpLen : 201.0
Train_AverageReturn : -269.3595275878906
Train_StdReturn : 7.059474945068359
Train_MaxReturn : -262.1835021972656
Train_MinReturn : -276.4802551269531
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 27336
TimeSinceStart : 348.64375829696655
Training Loss : 0.1616498827934265
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 10 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -296.89556884765625
Eval_StdReturn : 25.664642333984375
Eval_MaxReturn : -271.2309265136719
Eval_MinReturn : -322.5602111816406
Eval_AverageEpLen : 201.0
Train_AverageReturn : -261.3101501464844
Train_StdReturn : 15.11253547668457
Train_MaxReturn : -247.57574462890625
Train_MinReturn : -285.4844055175781
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 28140
TimeSinceStart : 384.61221742630005
Training Loss : 0.1554473638534546
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 11 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -284.3224792480469
Eval_StdReturn : 5.794891357421875
Eval_MaxReturn : -278.527587890625
Eval_MinReturn : -290.11737060546875
Eval_AverageEpLen : 201.0
Train_AverageReturn : -249.93511962890625
Train_StdReturn : 8.418220520019531
Train_MaxReturn : -236.8280029296875
Train_MinReturn : -260.0191955566406
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 28944
TimeSinceStart : 421.1351270675659
Training Loss : 0.15328046679496765
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 12 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -254.8817138671875
Eval_StdReturn : 1.6114425659179688
Eval_MaxReturn : -253.27027893066406
Eval_MinReturn : -256.4931640625
Eval_AverageEpLen : 201.0
Train_AverageReturn : -270.0320739746094
Train_StdReturn : 11.585246086120605
Train_MaxReturn : -258.54156494140625
Train_MinReturn : -287.05682373046875
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 29748
TimeSinceStart : 457.03587222099304
Training Loss : 0.15252582728862762
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 13 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -231.3693084716797
Eval_StdReturn : 6.2331695556640625
Eval_MaxReturn : -225.13613891601562
Eval_MinReturn : -237.60247802734375
Eval_AverageEpLen : 201.0
Train_AverageReturn : -272.7889099121094
Train_StdReturn : 8.14840316772461
Train_MaxReturn : -261.22900390625
Train_MinReturn : -283.2556457519531
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 30552
TimeSinceStart : 492.36489152908325
Training Loss : 0.15008573234081268
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 14 ************

Collecting data to be used for training...
At timestep:     201 / 800At timestep:     402 / 800At timestep:     603 / 800At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     201 / 400At timestep:     402 / 400Eval_AverageReturn : -275.8951721191406
Eval_StdReturn : 4.85272216796875
Eval_MaxReturn : -271.0424499511719
Eval_MinReturn : -280.7478942871094
Eval_AverageEpLen : 201.0
Train_AverageReturn : -264.60595703125
Train_StdReturn : 11.915542602539062
Train_MaxReturn : -248.3751220703125
Train_MinReturn : -281.6749572753906
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 31356
TimeSinceStart : 527.5254335403442
Training Loss : 0.15264248847961426
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...





LOGGING TO:  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q4_reacher_ensemble5_reacher-cs285-v0_02-11-2022_21-44-09 



########################
logging outputs to  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q4_reacher_ensemble5_reacher-cs285-v0_02-11-2022_21-44-09
########################
Using GPU id 0
Using action sampling strategy: random


********** Iteration 0 ************

Collecting data to be used for training...
At timestep:     201 / 20000At timestep:     402 / 20000At timestep:     603 / 20000At timestep:     804 / 20000At timestep:     1005 / 20000At timestep:     1206 / 20000At timestep:     1407 / 20000At timestep:     1608 / 20000At timestep:     1809 / 20000At timestep:     2010 / 20000At timestep:     2211 / 20000At timestep:     2412 / 20000At timestep:     2613 / 20000At timestep:     2814 / 20000At timestep:     3015 / 20000At timestep:     3216 / 20000At timestep:     3417 / 20000At timestep:     3618 / 20000At timestep:     3819 / 20000At timestep:     4020 / 20000At timestep:     4221 / 20000At timestep:     4422 / 20000At timestep:     4623 / 20000At timestep:     4824 / 20000At timestep:     5025 / 20000At timestep:     5226 / 20000At timestep:     5427 / 20000At timestep:     5628 / 20000At timestep:     5829 / 20000At timestep:     6030 / 20000At timestep:     6231 / 20000At timestep:     6432 / 20000At timestep:     6633 / 20000At timestep:     6834 / 20000At timestep:     7035 / 20000At timestep:     7236 / 20000At timestep:     7437 / 20000At timestep:     7638 / 20000At timestep:     7839 / 20000At timestep:     8040 / 20000At timestep:     8241 / 20000At timestep:     8442 / 20000At timestep:     8643 / 20000At timestep:     8844 / 20000At timestep:     9045 / 20000At timestep:     9246 / 20000At timestep:     9447 / 20000At timestep:     9648 / 20000At timestep:     9849 / 20000At timestep:     10050 / 20000At timestep:     10251 / 20000At timestep:     10452 / 20000At timestep:     10653 / 20000At timestep:     10854 / 20000At timestep:     11055 / 20000At timestep:     11256 / 20000At timestep:     11457 / 20000At timestep:     11658 / 20000At timestep:     11859 / 20000At timestep:     12060 / 20000At timestep:     12261 / 20000At timestep:     12462 / 20000At timestep:     12663 / 20000At timestep:     12864 / 20000At timestep:     13065 / 20000At timestep:     13266 / 20000At timestep:     13467 / 20000At timestep:     13668 / 20000At timestep:     13869 / 20000At timestep:     14070 / 20000At timestep:     14271 / 20000At timestep:     14472 / 20000At timestep:     14673 / 20000At timestep:     14874 / 20000At timestep:     15075 / 20000At timestep:     15276 / 20000At timestep:     15477 / 20000At timestep:     15678 / 20000At timestep:     15879 / 20000At timestep:     16080 / 20000At timestep:     16281 / 20000At timestep:     16482 / 20000At timestep:     16683 / 20000At timestep:     16884 / 20000At timestep:     17085 / 20000At timestep:     17286 / 20000At timestep:     17487 / 20000At timestep:     17688 / 20000At timestep:     17889 / 20000At timestep:     18090 / 20000At timestep:     18291 / 20000At timestep:     18492 / 20000At timestep:     18693 / 20000At timestep:     18894 / 20000At timestep:     19095 / 20000At timestep:     19296 / 20000At timestep:     19497 / 20000At timestep:     19698 / 20000At timestep:     19899 / 20000At timestep:     20100 / 20000
Training agent...

Beginning logging procedure...

Collecting data for eval...
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     201 / 400ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     402 / 400Eval_AverageReturn : -406.14031982421875
Eval_StdReturn : 24.838241577148438
Eval_MaxReturn : -381.3020935058594
Eval_MinReturn : -430.97857666015625
Eval_AverageEpLen : 201.0
Train_AverageReturn : -1887.0548095703125
Train_StdReturn : 400.1144714355469
Train_MaxReturn : -957.108154296875
Train_MinReturn : -2589.48681640625
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 20100
TimeSinceStart : 30.363072156906128
Training Loss : 0.19867922365665436
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     201 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     402 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     603 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     201 / 400ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     402 / 400Eval_AverageReturn : -288.6881103515625
Eval_StdReturn : 35.48119354248047
Eval_MaxReturn : -253.20692443847656
Eval_MinReturn : -324.1693115234375
Eval_AverageEpLen : 201.0
Train_AverageReturn : -432.564697265625
Train_StdReturn : 71.46610260009766
Train_MaxReturn : -367.07147216796875
Train_MinReturn : -551.58984375
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 20904
TimeSinceStart : 91.06313896179199
Training Loss : 0.1880514919757843
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 2 ************

Collecting data to be used for training...
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     201 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     402 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     603 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     201 / 400ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     402 / 400Eval_AverageReturn : -265.94293212890625
Eval_StdReturn : 9.492645263671875
Eval_MaxReturn : -256.4502868652344
Eval_MinReturn : -275.4355773925781
Eval_AverageEpLen : 201.0
Train_AverageReturn : -275.9388427734375
Train_StdReturn : 22.211021423339844
Train_MaxReturn : -258.5698547363281
Train_MinReturn : -312.92864990234375
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 21708
TimeSinceStart : 182.3801453113556
Training Loss : 0.17787297070026398
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 3 ************

Collecting data to be used for training...
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     201 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     402 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     603 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     201 / 400ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     402 / 400Eval_AverageReturn : -255.2715301513672
Eval_StdReturn : 5.8335418701171875
Eval_MaxReturn : -249.43798828125
Eval_MinReturn : -261.1050720214844
Eval_AverageEpLen : 201.0
Train_AverageReturn : -264.9079284667969
Train_StdReturn : 15.661454200744629
Train_MaxReturn : -245.63417053222656
Train_MinReturn : -288.3314514160156
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 22512
TimeSinceStart : 280.9889714717865
Training Loss : 0.1750185340642929
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 4 ************

Collecting data to be used for training...
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     201 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     402 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     603 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     201 / 400ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     402 / 400Eval_AverageReturn : -273.1821594238281
Eval_StdReturn : 1.3026123046875
Eval_MaxReturn : -271.8795471191406
Eval_MinReturn : -274.4847717285156
Eval_AverageEpLen : 201.0
Train_AverageReturn : -265.1897888183594
Train_StdReturn : 11.735025405883789
Train_MaxReturn : -250.99368286132812
Train_MinReturn : -283.1546936035156
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 23316
TimeSinceStart : 353.4434721469879
Training Loss : 0.17289993166923523
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 5 ************

Collecting data to be used for training...
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     201 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     402 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     603 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     201 / 400ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     402 / 400Eval_AverageReturn : -246.97476196289062
Eval_StdReturn : 7.813270568847656
Eval_MaxReturn : -239.16148376464844
Eval_MinReturn : -254.78802490234375
Eval_AverageEpLen : 201.0
Train_AverageReturn : -266.15911865234375
Train_StdReturn : 6.825106143951416
Train_MaxReturn : -255.95748901367188
Train_MinReturn : -274.7451171875
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 24120
TimeSinceStart : 411.4202992916107
Training Loss : 0.17171873152256012
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 6 ************

Collecting data to be used for training...
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     201 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     402 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     603 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     201 / 400ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     402 / 400Eval_AverageReturn : -268.4300537109375
Eval_StdReturn : 10.638107299804688
Eval_MaxReturn : -257.7919616699219
Eval_MinReturn : -279.06817626953125
Eval_AverageEpLen : 201.0
Train_AverageReturn : -267.1183776855469
Train_StdReturn : 10.509798049926758
Train_MaxReturn : -254.9120635986328
Train_MinReturn : -283.756103515625
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 24924
TimeSinceStart : 468.6963300704956
Training Loss : 0.16590414941310883
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 7 ************

Collecting data to be used for training...
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     201 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     402 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     603 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     201 / 400ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     402 / 400Eval_AverageReturn : -259.376220703125
Eval_StdReturn : 18.497268676757812
Eval_MaxReturn : -240.87896728515625
Eval_MinReturn : -277.8735046386719
Eval_AverageEpLen : 201.0
Train_AverageReturn : -264.5619812011719
Train_StdReturn : 11.120330810546875
Train_MaxReturn : -252.67784118652344
Train_MinReturn : -276.6439208984375
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 25728
TimeSinceStart : 525.867036819458
Training Loss : 0.1619562804698944
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 8 ************

Collecting data to be used for training...
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     201 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     402 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     603 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     201 / 400ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     402 / 400Eval_AverageReturn : -267.4303894042969
Eval_StdReturn : 19.48175811767578
Eval_MaxReturn : -247.94862365722656
Eval_MinReturn : -286.9121398925781
Eval_AverageEpLen : 201.0
Train_AverageReturn : -270.2083435058594
Train_StdReturn : 17.358488082885742
Train_MaxReturn : -255.12399291992188
Train_MinReturn : -299.72882080078125
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 26532
TimeSinceStart : 583.4689552783966
Training Loss : 0.16006194055080414
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 9 ************

Collecting data to be used for training...
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     201 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     402 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     603 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     201 / 400ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     402 / 400Eval_AverageReturn : -261.5570983886719
Eval_StdReturn : 3.753204345703125
Eval_MaxReturn : -257.80389404296875
Eval_MinReturn : -265.310302734375
Eval_AverageEpLen : 201.0
Train_AverageReturn : -258.7487487792969
Train_StdReturn : 8.787442207336426
Train_MaxReturn : -249.655517578125
Train_MinReturn : -273.0406799316406
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 27336
TimeSinceStart : 641.3382031917572
Training Loss : 0.16199424862861633
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 10 ************

Collecting data to be used for training...
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     201 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     402 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     603 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     201 / 400ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     402 / 400Eval_AverageReturn : -271.51141357421875
Eval_StdReturn : 7.8280487060546875
Eval_MaxReturn : -263.6833801269531
Eval_MinReturn : -279.3394775390625
Eval_AverageEpLen : 201.0
Train_AverageReturn : -266.8941650390625
Train_StdReturn : 17.37761878967285
Train_MaxReturn : -248.74676513671875
Train_MinReturn : -295.5306396484375
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 28140
TimeSinceStart : 698.4625556468964
Training Loss : 0.1577741652727127
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 11 ************

Collecting data to be used for training...
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     201 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     402 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     603 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     201 / 400ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     402 / 400Eval_AverageReturn : -308.26348876953125
Eval_StdReturn : 20.871566772460938
Eval_MaxReturn : -287.39190673828125
Eval_MinReturn : -329.1350402832031
Eval_AverageEpLen : 201.0
Train_AverageReturn : -261.6650085449219
Train_StdReturn : 10.49126148223877
Train_MaxReturn : -245.6432647705078
Train_MinReturn : -272.8826599121094
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 28944
TimeSinceStart : 755.1910984516144
Training Loss : 0.1544405221939087
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 12 ************

Collecting data to be used for training...
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     201 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     402 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     603 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     201 / 400ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     402 / 400Eval_AverageReturn : -302.0322265625
Eval_StdReturn : 4.2069549560546875
Eval_MaxReturn : -297.82525634765625
Eval_MinReturn : -306.2391662597656
Eval_AverageEpLen : 201.0
Train_AverageReturn : -265.80413818359375
Train_StdReturn : 9.835603713989258
Train_MaxReturn : -251.1297149658203
Train_MinReturn : -278.8147277832031
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 29748
TimeSinceStart : 813.1041498184204
Training Loss : 0.15332332253456116
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 13 ************

Collecting data to be used for training...
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     201 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     402 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     603 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     201 / 400ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     402 / 400Eval_AverageReturn : -250.9796142578125
Eval_StdReturn : 2.8033828735351562
Eval_MaxReturn : -248.17623901367188
Eval_MinReturn : -253.7830047607422
Eval_AverageEpLen : 201.0
Train_AverageReturn : -283.3992614746094
Train_StdReturn : 32.87604522705078
Train_MaxReturn : -249.3340301513672
Train_MinReturn : -336.1032409667969
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 30552
TimeSinceStart : 871.5885593891144
Training Loss : 0.14918982982635498
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...




********** Iteration 14 ************

Collecting data to be used for training...
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     201 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     402 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     603 / 800ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     804 / 800
Training agent...

Beginning logging procedure...

Collecting data for eval...
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     201 / 400ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/core.py:257: DeprecationWarning: [33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.[0m
  "Function `env.seed(seed)` is marked as deprecated and will be removed in the future. "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  "Core environment is written in old step API which returns one bool instead of two. "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:235: UserWarning: [33mWARN: Expects `done` signal to be a boolean, actual type: <class 'numpy.float64'>[0m
  f"Expects `done` signal to be a boolean, actual type: {type(done)}"
 (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
ttttt (7,)
At timestep:     402 / 400Eval_AverageReturn : -277.3231506347656
Eval_StdReturn : 22.62543487548828
Eval_MaxReturn : -254.6977081298828
Eval_MinReturn : -299.9485778808594
Eval_AverageEpLen : 201.0
Train_AverageReturn : -268.6336975097656
Train_StdReturn : 14.480707168579102
Train_MaxReturn : -254.47366333007812
Train_MinReturn : -289.7024230957031
Train_AverageEpLen : 201.0
Train_EnvstepsSoFar : 31356
TimeSinceStart : 930.3622512817383
Training Loss : 0.15138252079486847
Initial_DataCollection_AverageReturn : -1887.0548095703125
Done logging...


