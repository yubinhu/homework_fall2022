/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/core.py:257: DeprecationWarning: [33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.[0m
  "Function `env.seed(seed)` is marked as deprecated and will be removed in the future. "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/seeding.py:54: DeprecationWarning: [33mWARN: Function `rng.randn(*size)` is marked as deprecated and will be removed in the future. Please use `rng.standard_normal(size)` instead.[0m
  "Function `rng.randn(*size)` is marked as deprecated "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  "Core environment is written in old step API which returns one bool instead of two. "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:235: UserWarning: [33mWARN: Expects `done` signal to be a boolean, actual type: <class 'numpy.float64'>[0m
  f"Expects `done` signal to be a boolean, actual type: {type(done)}"
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/seeding.py:54: DeprecationWarning: [33mWARN: Function `rng.randn(*size)` is marked as deprecated and will be removed in the future. Please use `rng.standard_normal(size)` instead.[0m
  "Function `rng.randn(*size)` is marked as deprecated "



LOGGING TO:  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q5_cheetah_random_cheetah-cs285-v0_03-11-2022_11-26-00 



########################
logging outputs to  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q5_cheetah_random_cheetah-cs285-v0_03-11-2022_11-26-00
########################
Using GPU id 0
Using action sampling strategy: random


********** Iteration 0 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 107.58357238769531
Eval_StdReturn : 0.0
Eval_MaxReturn : 107.58357238769531
Eval_MinReturn : 107.58357238769531
Eval_AverageEpLen : 501.0
Train_AverageReturn : -2501.908447265625
Train_StdReturn : 326.896728515625
Train_MaxReturn : -2060.5048828125
Train_MinReturn : -3182.69873046875
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 5010
TimeSinceStart : 22.4207444190979
Training Loss : 0.07185449451208115
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 209.3043670654297
Eval_StdReturn : 0.0
Eval_MaxReturn : 209.3043670654297
Eval_MinReturn : 209.3043670654297
Eval_AverageEpLen : 501.0
Train_AverageReturn : 113.9879150390625
Train_StdReturn : 18.405832290649414
Train_MaxReturn : 138.06491088867188
Train_MinReturn : 72.23675537109375
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 10020
TimeSinceStart : 196.7190318107605
Training Loss : 0.0936899408698082
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 2 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 277.6873779296875
Eval_StdReturn : 0.0
Eval_MaxReturn : 277.6873779296875
Eval_MinReturn : 277.6873779296875
Eval_AverageEpLen : 501.0
Train_AverageReturn : 180.22604370117188
Train_StdReturn : 17.92595100402832
Train_MaxReturn : 206.318115234375
Train_MinReturn : 140.17733764648438
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 15030
TimeSinceStart : 380.9111919403076
Training Loss : 0.09945505112409592
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 3 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 290.08270263671875
Eval_StdReturn : 0.0
Eval_MaxReturn : 290.08270263671875
Eval_MinReturn : 290.08270263671875
Eval_AverageEpLen : 501.0
Train_AverageReturn : 242.5041961669922
Train_StdReturn : 29.039445877075195
Train_MaxReturn : 294.29449462890625
Train_MinReturn : 199.9846649169922
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 20040
TimeSinceStart : 567.1177949905396
Training Loss : 0.10085862874984741
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 4 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 262.9917297363281
Eval_StdReturn : 0.0
Eval_MaxReturn : 262.9917297363281
Eval_MinReturn : 262.9917297363281
Eval_AverageEpLen : 501.0
Train_AverageReturn : 255.3231658935547
Train_StdReturn : 35.30226516723633
Train_MaxReturn : 296.37847900390625
Train_MinReturn : 194.86993408203125
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 25050
TimeSinceStart : 761.2222542762756
Training Loss : 0.09802386909723282
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...


/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/core.py:257: DeprecationWarning: [33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.[0m
  "Function `env.seed(seed)` is marked as deprecated and will be removed in the future. "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/seeding.py:54: DeprecationWarning: [33mWARN: Function `rng.randn(*size)` is marked as deprecated and will be removed in the future. Please use `rng.standard_normal(size)` instead.[0m
  "Function `rng.randn(*size)` is marked as deprecated "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  "Core environment is written in old step API which returns one bool instead of two. "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:235: UserWarning: [33mWARN: Expects `done` signal to be a boolean, actual type: <class 'numpy.float64'>[0m
  f"Expects `done` signal to be a boolean, actual type: {type(done)}"
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/seeding.py:54: DeprecationWarning: [33mWARN: Function `rng.randn(*size)` is marked as deprecated and will be removed in the future. Please use `rng.standard_normal(size)` instead.[0m
  "Function `rng.randn(*size)` is marked as deprecated "



LOGGING TO:  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q5_cheetah_cem_2_cheetah-cs285-v0_03-11-2022_11-38-44 



########################
logging outputs to  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q5_cheetah_cem_2_cheetah-cs285-v0_03-11-2022_11-38-44
########################
Using GPU id 0
Using action sampling strategy: cem
CEM params: alpha=1, num_elites=5, iterations=2


********** Iteration 0 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 102.87206268310547
Eval_StdReturn : 0.0
Eval_MaxReturn : 102.87206268310547
Eval_MinReturn : 102.87206268310547
Eval_AverageEpLen : 501.0
Train_AverageReturn : -2501.908447265625
Train_StdReturn : 326.896728515625
Train_MaxReturn : -2060.5048828125
Train_MinReturn : -3182.69873046875
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 5010
TimeSinceStart : 44.134615659713745
Training Loss : 0.07185449451208115
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 239.13714599609375
Eval_StdReturn : 0.0
Eval_MaxReturn : 239.13714599609375
Eval_MinReturn : 239.13714599609375
Eval_AverageEpLen : 501.0
Train_AverageReturn : 116.87125396728516
Train_StdReturn : 14.744481086730957
Train_MaxReturn : 137.60939025878906
Train_MinReturn : 93.30868530273438
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 10020
TimeSinceStart : 418.88385367393494
Training Loss : 0.10276047140359879
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 2 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 365.01727294921875
Eval_StdReturn : 0.0
Eval_MaxReturn : 365.01727294921875
Eval_MinReturn : 365.01727294921875
Eval_AverageEpLen : 501.0
Train_AverageReturn : 225.9232635498047
Train_StdReturn : 19.574399948120117
Train_MaxReturn : 254.70068359375
Train_MinReturn : 194.37200927734375
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 15030
TimeSinceStart : 797.0283589363098
Training Loss : 0.106545090675354
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 3 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 416.202880859375
Eval_StdReturn : 0.0
Eval_MaxReturn : 416.202880859375
Eval_MinReturn : 416.202880859375
Eval_AverageEpLen : 501.0
Train_AverageReturn : 303.625
Train_StdReturn : 11.33354377746582
Train_MaxReturn : 321.56903076171875
Train_MinReturn : 290.8428955078125
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 20040
TimeSinceStart : 1177.3699688911438
Training Loss : 0.11051709204912186
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 4 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 486.0643310546875
Eval_StdReturn : 0.0
Eval_MaxReturn : 486.0643310546875
Eval_MinReturn : 486.0643310546875
Eval_AverageEpLen : 501.0
Train_AverageReturn : 378.656005859375
Train_StdReturn : 31.860258102416992
Train_MaxReturn : 447.842529296875
Train_MinReturn : 329.8012390136719
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 25050
TimeSinceStart : 1561.202092409134
Training Loss : 0.10565157979726791
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...


/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/core.py:318: DeprecationWarning: [33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: [33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.[0m
  "Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future."
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/core.py:257: DeprecationWarning: [33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.[0m
  "Function `env.seed(seed)` is marked as deprecated and will be removed in the future. "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/seeding.py:54: DeprecationWarning: [33mWARN: Function `rng.randn(*size)` is marked as deprecated and will be removed in the future. Please use `rng.standard_normal(size)` instead.[0m
  "Function `rng.randn(*size)` is marked as deprecated "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. [0m
  "Core environment is written in old step API which returns one bool instead of two. "
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/passive_env_checker.py:235: UserWarning: [33mWARN: Expects `done` signal to be a boolean, actual type: <class 'numpy.float64'>[0m
  f"Expects `done` signal to be a boolean, actual type: {type(done)}"
/home/harvey/anaconda3/envs/cs285/lib/python3.7/site-packages/gym/utils/seeding.py:54: DeprecationWarning: [33mWARN: Function `rng.randn(*size)` is marked as deprecated and will be removed in the future. Please use `rng.standard_normal(size)` instead.[0m
  "Function `rng.randn(*size)` is marked as deprecated "



LOGGING TO:  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q5_cheetah_cem_4_cheetah-cs285-v0_03-11-2022_12-04-49 



########################
logging outputs to  /home/harvey/Documents/cs285/homework_fall2022/hw4/cs285/scripts/../../data/hw4_q5_cheetah_cem_4_cheetah-cs285-v0_03-11-2022_12-04-49
########################
Using GPU id 0
Using action sampling strategy: cem
CEM params: alpha=1, num_elites=5, iterations=4


********** Iteration 0 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 204.62315368652344
Eval_StdReturn : 0.0
Eval_MaxReturn : 204.62315368652344
Eval_MinReturn : 204.62315368652344
Eval_AverageEpLen : 501.0
Train_AverageReturn : -2501.908447265625
Train_StdReturn : 326.896728515625
Train_MaxReturn : -2060.5048828125
Train_MinReturn : -3182.69873046875
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 5010
TimeSinceStart : 83.79134321212769
Training Loss : 0.07185449451208115
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 1 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 514.4876708984375
Eval_StdReturn : 0.0
Eval_MaxReturn : 514.4876708984375
Eval_MinReturn : 514.4876708984375
Eval_AverageEpLen : 501.0
Train_AverageReturn : 220.80978393554688
Train_StdReturn : 18.27657699584961
Train_MaxReturn : 249.0439453125
Train_MinReturn : 191.8892822265625
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 10020
TimeSinceStart : 876.0131115913391
Training Loss : 0.10690657049417496
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 2 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 632.50390625
Eval_StdReturn : 0.0
Eval_MaxReturn : 632.50390625
Eval_MinReturn : 632.50390625
Eval_AverageEpLen : 501.0
Train_AverageReturn : 478.55230712890625
Train_StdReturn : 19.569475173950195
Train_MaxReturn : 524.4200439453125
Train_MinReturn : 455.2088623046875
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 15030
TimeSinceStart : 1665.3651340007782
Training Loss : 0.11425280570983887
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 3 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 671.9439697265625
Eval_StdReturn : 0.0
Eval_MaxReturn : 671.9439697265625
Eval_MinReturn : 671.9439697265625
Eval_AverageEpLen : 501.0
Train_AverageReturn : 687.9150390625
Train_StdReturn : 36.68600082397461
Train_MaxReturn : 748.30224609375
Train_MinReturn : 616.66357421875
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 20040
TimeSinceStart : 2466.587949991226
Training Loss : 0.10958510637283325
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...




********** Iteration 4 ************

Collecting data to be used for training...
At timestep:     501 / 5000At timestep:     1002 / 5000At timestep:     1503 / 5000At timestep:     2004 / 5000At timestep:     2505 / 5000At timestep:     3006 / 5000At timestep:     3507 / 5000At timestep:     4008 / 5000At timestep:     4509 / 5000At timestep:     5010 / 5000
Training agent...

Beginning logging procedure...

Collecting data for eval...
At timestep:     501 / 400Eval_AverageReturn : 771.5823974609375
Eval_StdReturn : 0.0
Eval_MaxReturn : 771.5823974609375
Eval_MinReturn : 771.5823974609375
Eval_AverageEpLen : 501.0
Train_AverageReturn : 691.3604736328125
Train_StdReturn : 42.779747009277344
Train_MaxReturn : 760.379150390625
Train_MinReturn : 607.8319091796875
Train_AverageEpLen : 501.0
Train_EnvstepsSoFar : 25050
TimeSinceStart : 3258.58544421196
Training Loss : 0.10909837484359741
Initial_DataCollection_AverageReturn : -2501.908447265625
Done logging...


